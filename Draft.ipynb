{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Multi-layer ANN\n",
    "\n",
    "Hyperparameters:\n",
    " 1. Number of nodes\n",
    " 2. Number of layers\n",
    " 3. Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from enum import Enum\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>blast_furnace_slag</th>\n",
       "      <th>fly_ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>coarse_aggregate</th>\n",
       "      <th>fine_aggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>concrete_compressive_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement  blast_furnace_slag  fly_ash  water  superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   coarse_aggregate  fine_aggregate   age  concrete_compressive_strength  \n",
       "0            1040.0            676.0   28                          79.99  \n",
       "1            1055.0            676.0   28                          61.89  \n",
       "2             932.0            594.0  270                          40.27  \n",
       "3             932.0            594.0  365                          41.05  \n",
       "4             978.4            825.5  360                          44.30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "concrete = pd.read_csv('data/concrete_data.csv')\n",
    "concrete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X and Y\n",
    "# Then separate test and train set\n",
    "# Also do the Cross-Validation (optional)\n",
    "X = concrete.drop('concrete_compressive_strength', axis = 1)\n",
    "y = concrete['concrete_compressive_strength']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function\n",
    "def logistic(x):\n",
    "    return 1/(1 + math.exp(-x))\n",
    "\n",
    "def ReLU(x):\n",
    "    return max(0, x)\n",
    "\n",
    "def hyperbolic(x):\n",
    "    return math.tanh(x)\n",
    "\n",
    "class ActFunc(Enum):\n",
    "    log = logistic\n",
    "    relu = ReLU\n",
    "    hb = hyperbolic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network test!\n",
    "from neuralNet import neuralNet\n",
    "from layer import layer\n",
    "\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.hb, 10))\n",
    "network.add(layer(ActFunc.relu,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying NN on the concrete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current best mae: 30.00410467208457\n",
      "Current best mae: 29.52284473300973\n",
      "Current best mae: 27.98827733046079\n",
      "Current best mae: 27.89193786119894\n",
      "Current best mae: 26.275125481798863\n",
      "Current best mae: 26.009996955930486\n",
      "Current best mae: 24.768910647272236\n",
      "Current best mae: 24.67338085258098\n",
      "Current best mae: 23.471577237922716\n",
      "Current best mae: 22.797737269789405\n",
      "Current best mae: 22.14391914486775\n",
      "Current best mae: 21.98859840767058\n",
      "Current best mae: 21.48388625324952\n",
      "Current best mae: 20.738706709608255\n",
      "Current best mae: 20.471153453900744\n",
      "Current best mae: 19.685623783828742\n",
      "Current best mae: 19.264198829674218\n",
      "Current best mae: 18.886673145442902\n",
      "Current best mae: 18.320969219413023\n",
      "Current best mae: 18.06077277853479\n",
      "Current best mae: 17.869642048028282\n",
      "Current best mae: 17.579433022105164\n",
      "Final best mae 17.579433022105164\n"
     ]
    }
   ],
   "source": [
    "# PSO test!\n",
    "import pso\n",
    "\n",
    "swarmsize = 10\n",
    "alpha = 0.7\n",
    "beta = 2\n",
    "gamma = 1.5\n",
    "delta = 1.5\n",
    "epsilon = 0.4\n",
    "n_iter = 10\n",
    "\n",
    "particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter)\n",
    "opti_particle, best_mae_arr = particle_swarm_opti.optimise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potential ranges of PSO parameters to try\n",
    "# Could try them like a gridsearch but its probably a bit too much for that, tuning one at a time is probably the way to go\n",
    "\n",
    "alphaRange = np.arange(0.4,0.9,0.1)\n",
    "betaRange = np.arange(1.5,2.5,0.1)\n",
    "gammaRange = np.arange(1.5,2.5,0.1)\n",
    "deltaRange = np.arange(1.5,2.5,0.1)\n",
    "epsilonRange = np.arange(0.1,0.5,0.1) # not sure about the range of the learning rate, might need to experiment or look for more sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha tuning\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for alpha in alphaRange:\n",
    "    network = neuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current best mae: 33.18710708846312\n",
      "Current best mae: 32.58017481868509\n",
      "Current best mae: 32.133144562680656\n",
      "Current best mae: 31.300867647261608\n",
      "Current best mae: 30.76489954750443\n",
      "Current best mae: 30.425243145269768\n",
      "Current best mae: 30.36212661270656\n",
      "Current best mae: 29.978573510558036\n",
      "Current best mae: 29.174864873074256\n",
      "Current best mae: 29.07512028570915\n",
      "Current best mae: 28.7120382544829\n",
      "Current best mae: 27.68508988970189\n",
      "Current best mae: 27.570786754908095\n",
      "Current best mae: 27.53204574180525\n",
      "Current best mae: 27.480306799809174\n",
      "Current best mae: 27.412671697852517\n",
      "Current best mae: 26.010339424970198\n",
      "Current best mae: 25.80237649401427\n",
      "Current best mae: 24.582267303294394\n",
      "Current best mae: 24.43276833235693\n",
      "Current best mae: 23.31403926631566\n",
      "Current best mae: 23.079620539359404\n",
      "Current best mae: 22.230529565216134\n",
      "Current best mae: 22.14854923527954\n",
      "Current best mae: 22.049729257377887\n",
      "Current best mae: 21.972991521850492\n",
      "Current best mae: 21.272900973044113\n",
      "Current best mae: 21.233397758268016\n",
      "Current best mae: 21.13859373976074\n",
      "Current best mae: 20.568970939641677\n",
      "Current best mae: 20.564607766088397\n",
      "Final best mae 20.564607766088397\n",
      "Current best mae: 33.46191935334544\n",
      "Current best mae: 32.18798106580918\n",
      "Current best mae: 30.181423375257562\n",
      "Current best mae: 28.494251492492864\n",
      "Current best mae: 24.570570918756058\n",
      "Current best mae: 24.382474616590823\n",
      "Current best mae: 24.051659426147296\n",
      "Current best mae: 23.383463896621958\n",
      "Current best mae: 17.435344601008204\n",
      "Current best mae: 13.695455359891755\n",
      "Current best mae: 13.140825577062744\n",
      "Current best mae: 12.757121957123084\n",
      "Current best mae: 12.73736161444772\n",
      "Current best mae: 12.733348010924335\n",
      "Current best mae: 12.72089212561704\n",
      "Final best mae 12.72089212561704\n",
      "Current best mae: 27.39951045455522\n",
      "Current best mae: 20.87076104432318\n",
      "Current best mae: 18.426578948580477\n",
      "Current best mae: 12.743652254605388\n",
      "Current best mae: 12.719370699941406\n",
      "Current best mae: 12.718980124803672\n",
      "Final best mae 12.718980124803672\n",
      "Current best mae: 19.528641610514164\n",
      "Current best mae: 15.354789849645243\n",
      "Current best mae: 13.013891840319314\n",
      "Current best mae: 12.718731750994262\n",
      "Final best mae 12.718731750994262\n"
     ]
    }
   ],
   "source": [
    "# Try neural network architectures\n",
    "# 2-10 layers\n",
    "# 3-10 neurons per layer\n",
    "\n",
    "layers = range(1, 5) # 1 to x hidden layer\n",
    "#neurons = range(2, 30) # 2 to 30 neurons\n",
    "# Try different layers\n",
    "# Constant 4 neurons per layer, activation func relu\n",
    "\n",
    "accuraciesForLayers = []\n",
    "for numLayers in layers:\n",
    "    network = neuralNet()\n",
    "    network.add(layer(ActFunc.hb,4))\n",
    "    for i in range(numLayers - 1):\n",
    "        network.add(layer(ActFunc.relu,4))\n",
    "    network.add(layer(ActFunc.relu, 1)) # output layer\n",
    "    layerTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter,prints=False)\n",
    "    opti_particle, best_mae_arr = layerTestPSO.optimise()\n",
    "    accuraciesForLayers.append(best_mae_arr[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20.564607766088397, 12.72089212561704, 12.718980124803672, 12.718731750994262]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuraciesForLayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = range(3,11)\n",
    "\n",
    "accuraciesForNeuronCounts = []\n",
    "\n",
    "for neuronCount in neurons:\n",
    "    network = neuralNet()\n",
    "    network.add(layer(ActFunc.hb,neuronCount))\n",
    "    for i in range(4):\n",
    "        network.add(layer(ActFunc.relu,neuronCount))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    neuronsTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter,prints=False)\n",
    "    opti_particle, best_mae_arr = neuronsTestPSO.optimise()\n",
    "    accuraciesForNeuronCounts.append(best_mae_arr[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.720326536247986,\n",
       " 12.719297901296846,\n",
       " 12.738942461653247,\n",
       " 12.92201891593844,\n",
       " 12.749487660926423,\n",
       " 13.44267954441739,\n",
       " 13.915180511126492,\n",
       " 12.149197636654216]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuraciesForNeuronCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuraciesForAlphas = []\n",
    "\n",
    "for a in alphaRange:\n",
    "    network = neuralNet()\n",
    "    network.add(layer(ActFunc.hb,10))\n",
    "    for i in range(4):\n",
    "        network.add(layer(ActFunc.relu,10))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    alphaTestPSO = pso.PSO(X_train, y_train, network, swarmsize, a, beta, gamma, delta, epsilon, n_iter,prints=False)\n",
    "    opti_particle, best_mae_arr = alphaTestPSO.optimise()\n",
    "    accuraciesForAlphas.append(best_mae_arr[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m network\u001b[38;5;241m.\u001b[39madd(layer(ActFunc\u001b[38;5;241m.\u001b[39mrelu,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      9\u001b[0m betaTestPSO \u001b[38;5;241m=\u001b[39m pso\u001b[38;5;241m.\u001b[39mPSO(X_train, y_train, network, swarmsize, alpha, b, gamma, delta, epsilon, n_iter,prints\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 10\u001b[0m opti_particle, best_mae_arr \u001b[38;5;241m=\u001b[39m betaTestPSO\u001b[38;5;241m.\u001b[39moptimise()\n\u001b[0;32m     11\u001b[0m accuraciesForBetas\u001b[38;5;241m.\u001b[39mappend(best_mae_arr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\chany\\OneDrive\\Desktop\\Academic\\MSc\\Biological Inspired Computing\\CW\\pso.py:129\u001b[0m, in \u001b[0;36mPSO.optimise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    127\u001b[0m x_star \u001b[38;5;241m=\u001b[39m particle\u001b[38;5;241m.\u001b[39mprevBest\n\u001b[0;32m    128\u001b[0m x_plus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfittestLoc(particle\u001b[38;5;241m.\u001b[39minformant)\n\u001b[1;32m--> 129\u001b[0m x_prime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfittestLoc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparticles)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# Do the change velo\u001b[39;00m\n\u001b[0;32m    132\u001b[0m particle\u001b[38;5;241m.\u001b[39mchangeVelo(particle\u001b[38;5;241m.\u001b[39mpos, x_star, x_plus, x_prime)\n",
      "File \u001b[1;32mc:\\Users\\chany\\OneDrive\\Desktop\\Academic\\MSc\\Biological Inspired Computing\\CW\\pso.py:53\u001b[0m, in \u001b[0;36mPSO.fittestLoc\u001b[1;34m(self, someParticles)\u001b[0m\n\u001b[0;32m     51\u001b[0m fittest_mae \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m someParticles: \u001b[38;5;66;03m# supposed to be particle instead of list\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m     mae \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massessFitness(p\u001b[38;5;241m.\u001b[39mpos, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my)\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fittest_mae \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m mae \u001b[38;5;241m<\u001b[39m fittest_mae:\n\u001b[0;32m     55\u001b[0m         fittest_mae \u001b[38;5;241m=\u001b[39m mae\n",
      "File \u001b[1;32mc:\\Users\\chany\\OneDrive\\Desktop\\Academic\\MSc\\Biological Inspired Computing\\CW\\pso.py:87\u001b[0m, in \u001b[0;36mPSO.assessFitness\u001b[1;34m(self, pos, y)\u001b[0m\n\u001b[0;32m     84\u001b[0m weights_arr, bias_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massessFitness_helper(pos)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Calculate the pred y\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m yhat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mforwardCalculation, args \u001b[38;5;241m=\u001b[39m (weights_arr, bias_arr), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     88\u001b[0m mae \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39msseCalculation(yhat, y)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mae\n",
      "File \u001b[1;32mc:\\Users\\chany\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\chany\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\chany\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\chany\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\chany\\OneDrive\\Desktop\\Academic\\MSc\\Biological Inspired Computing\\CW\\neuralNet.py:14\u001b[0m, in \u001b[0;36mneuralNet.forwardCalculation\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m     12\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 14\u001b[0m     output \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mlayerCalculation(\u001b[38;5;28minput\u001b[39m, weight[i], bias[i])\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m     16\u001b[0m     i \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\chany\\OneDrive\\Desktop\\Academic\\MSc\\Biological Inspired Computing\\CW\\layer.py:33\u001b[0m, in \u001b[0;36mlayer.layerCalculation\u001b[1;34m(self, inputs, weights, bias)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# initialize all weights as 1 in case we do not have any specified\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# it is now an 2D array, lists containing weights for a single neuron (one weight for each input) grouped into a list (one list of weights for every neuron)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# if weights == None:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# if bias == None:\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#     self.bias = [1] * len(self.perceptronArr)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, perc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperceptronArr):\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput[i] \u001b[38;5;241m=\u001b[39m perc\u001b[38;5;241m.\u001b[39mCalculateOutput(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[i], \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39minputs, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias[i])\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\n",
      "File \u001b[1;32mc:\\Users\\chany\\OneDrive\\Desktop\\Academic\\MSc\\Biological Inspired Computing\\CW\\perceptron.py:12\u001b[0m, in \u001b[0;36mPerceptron.CalculateOutput\u001b[1;34m(self, weights, input, bias)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mCalculateOutput\u001b[39m(\u001b[38;5;28mself\u001b[39m, weights, \u001b[38;5;28minput\u001b[39m, bias):\n\u001b[1;32m---> 12\u001b[0m     z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28minput\u001b[39m)\u001b[38;5;241m.\u001b[39mT,np\u001b[38;5;241m.\u001b[39marray(weights)) \u001b[38;5;241m+\u001b[39m bias\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivationFunc(z)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuraciesForBetas = []\n",
    "\n",
    "for b in betaRange:\n",
    "    network = neuralNet()\n",
    "    network.add(layer(ActFunc.hb,10))\n",
    "    for i in range(4):\n",
    "        network.add(layer(ActFunc.relu,10))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    betaTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, b, gamma, delta, epsilon, n_iter,prints=False)\n",
    "    opti_particle, best_mae_arr = betaTestPSO.optimise()\n",
    "    accuraciesForBetas.append(best_mae_arr[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuraciesForGammas = []\n",
    "\n",
    "for g in gammaRange:\n",
    "    network = neuralNet()\n",
    "    network.add(layer(ActFunc.hb,10))\n",
    "    for i in range(4):\n",
    "        network.add(layer(ActFunc.relu,10))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    gammaTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, g, delta, epsilon, n_iter,prints=False)\n",
    "    opti_particle, best_mae_arr = gammaTestPSO.optimise()\n",
    "    accuraciesForGammas.append(best_mae_arr[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuraciesForDeltas = []\n",
    "\n",
    "for d in deltaRange:\n",
    "    network = neuralNet()\n",
    "    network.add(layer(ActFunc.hb,10))\n",
    "    for i in range(4):\n",
    "        network.add(layer(ActFunc.relu,10))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    deltaTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, d, epsilon, n_iter,prints=False)\n",
    "    opti_particle, best_mae_arr = deltaTestPSO.optimise()\n",
    "    accuraciesForDeltas.append(best_mae_arr[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuraciesForEpsilons = []\n",
    "\n",
    "for e in epsilonRange:\n",
    "    network = neuralNet()\n",
    "    network.add(layer(ActFunc.hb,10))\n",
    "    for i in range(4):\n",
    "        network.add(layer(ActFunc.relu,10))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    epsilonTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, e, n_iter,prints=False)\n",
    "    opti_particle, best_mae_arr = epsilonTestPSO.optimise()\n",
    "    accuraciesForEpsilons.append(best_mae_arr[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16.420837013206647,\n",
       " 12.720444335810935,\n",
       " 12.718655332856695,\n",
       " 12.722071306269948,\n",
       " 12.719791479367064]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuraciesForAlphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuraciesForBetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuraciesForGammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuraciesForDeltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuraciesForEpsilons"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
