{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Multi-layer ANN\n",
    "\n",
    "Hyperparameters:\n",
    " 1. Number of nodes\n",
    " 2. Number of layers\n",
    " 3. Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from enum import Enum\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>blast_furnace_slag</th>\n",
       "      <th>fly_ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>coarse_aggregate</th>\n",
       "      <th>fine_aggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>concrete_compressive_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement  blast_furnace_slag  fly_ash  water  superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   coarse_aggregate  fine_aggregate   age  concrete_compressive_strength  \n",
       "0            1040.0            676.0   28                          79.99  \n",
       "1            1055.0            676.0   28                          61.89  \n",
       "2             932.0            594.0  270                          40.27  \n",
       "3             932.0            594.0  365                          41.05  \n",
       "4             978.4            825.5  360                          44.30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "concrete = pd.read_csv('data/concrete_data.csv')\n",
    "concrete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X and Y\n",
    "# Then separate test and train set\n",
    "# Also do the Cross-Validation (optional)\n",
    "X = concrete.drop('concrete_compressive_strength', axis = 1)\n",
    "y = concrete['concrete_compressive_strength']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.head()\n",
    "y_train = y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function\n",
    "def logistic(x):\n",
    "    return 1/(1 + math.exp(-x))\n",
    "\n",
    "def ReLU(x):\n",
    "    return max(0, x)\n",
    "\n",
    "def hyperbolic(x):\n",
    "    return math.tanh(x)\n",
    "\n",
    "def leakyReLU(x):\n",
    "    return max(0.1*x, x)\n",
    "\n",
    "class ActFunc(Enum):\n",
    "    log = logistic\n",
    "    relu = ReLU\n",
    "    hb = hyperbolic\n",
    "    lRelu = leakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network test!\n",
    "from neuralNet import neuralNet\n",
    "from layer import layer\n",
    "\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu, 32))\n",
    "network.add(layer(ActFunc.hb, 64))\n",
    "network.add(layer(ActFunc.log, 128))\n",
    "network.add(layer(ActFunc.relu, 1))\n",
    "# network.add(layer(ActFunc.relu, 32))\n",
    "# network.add(layer(ActFunc.relu, 64))\n",
    "# network.add(layer(ActFunc.relu, 128))\n",
    "# network.add(layer(ActFunc.relu, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying NN on the concrete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current best mae: 34.338\n",
      "Current best mae: 32.7529694210205\n",
      "Current best mae: 28.612568981906065\n",
      "Current best mae: 27.971339540736686\n",
      "Current best mae: 26.644353748823317\n",
      "Current best mae: 26.549146224206844\n",
      "Current best mae: 24.641139946663824\n",
      "Current best mae: 23.402834435563943\n",
      "Current best mae: 22.912784355571638\n",
      "Current best mae: 22.791003321268768\n",
      "Current best mae: 21.756439969178942\n",
      "Current best mae: 21.56394635096\n",
      "Current best mae: 20.54023895161038\n",
      "Current best mae: 19.160247492245805\n",
      "Current best mae: 16.45716552076347\n",
      "Current best mae: 14.64474808206337\n",
      "Current best mae: 14.628386969976415\n",
      "Current best mae: 14.29883888091588\n",
      "Current best mae: 12.123206672541349\n",
      "Current best mae: 11.722661961106859\n",
      "Current best mae: 10.508106219619942\n",
      "Current best mae: 10.264336800470964\n",
      "Current best mae: 10.224454858931058\n",
      "Current best mae: 10.009864274782885\n",
      "Current best mae: 9.682997550201215\n",
      "Current best mae: 9.466421956650247\n",
      "Current best mae: 9.203946931356082\n",
      "Current best mae: 9.182852665822404\n",
      "Current best mae: 9.156442608260917\n",
      "Current best mae: 7.958678746380571\n",
      "Current best mae: 7.515578913876591\n",
      "Current best mae: 7.146787623884755\n",
      "Current best mae: 6.707066988673056\n",
      "Current best mae: 6.312424622638294\n",
      "Current best mae: 5.933205409502172\n",
      "Current best mae: 5.83311582031578\n",
      "Current best mae: 5.810969158115269\n",
      "Current best mae: 5.537275261946803\n",
      "Current best mae: 5.461784356890391\n",
      "Current best mae: 5.212627560150484\n",
      "Current best mae: 5.061993307051257\n",
      "Current best mae: 5.006451941468707\n",
      "Current best mae: 4.7852726755595265\n",
      "Current best mae: 4.772994657521648\n",
      "Current best mae: 4.763339358569892\n",
      "Current best mae: 4.727808933155784\n",
      "Current best mae: 4.684822765444275\n",
      "Current best mae: 4.665509190774004\n",
      "Current best mae: 4.653193319551938\n",
      "Current best mae: 4.652542179855621\n",
      "Current best mae: 4.647118370240896\n",
      "Current best mae: 4.613178533626294\n",
      "Current best mae: 4.5972175213564\n",
      "Current best mae: 4.592572330616557\n",
      "Current best mae: 4.557831201665331\n",
      "Current best mae: 4.540514245936822\n",
      "Current best mae: 4.515865121817319\n",
      "Current best mae: 4.5087069822434565\n",
      "Current best mae: 4.497391234200042\n",
      "Current best mae: 4.471305096810571\n",
      "Current best mae: 4.462960681135217\n",
      "Current best mae: 4.451703249409517\n",
      "Current best mae: 4.4410420841177105\n",
      "Current best mae: 4.439041388673749\n",
      "Current best mae: 4.424649547095446\n",
      "Current best mae: 4.379301447243087\n",
      "Current best mae: 4.365479347843113\n",
      "Current best mae: 4.328343237363744\n",
      "Current best mae: 4.327089020913794\n",
      "Current best mae: 4.325607698547037\n",
      "Current best mae: 4.321214769302752\n",
      "Current best mae: 4.308719267465533\n",
      "Current best mae: 4.307948101161552\n",
      "Current best mae: 4.3011002868239245\n",
      "Current best mae: 4.2802859532929345\n",
      "Current best mae: 4.257755140444627\n",
      "Current best mae: 4.236079416090398\n",
      "Current best mae: 4.23471983780768\n",
      "Current best mae: 4.230937629992203\n",
      "Current best mae: 4.228760311844175\n",
      "Current best mae: 4.216747280234192\n",
      "Current best mae: 4.21377906286789\n",
      "Current best mae: 4.212098744286292\n",
      "Current best mae: 4.209075512784808\n",
      "Current best mae: 4.205027202255618\n",
      "Current best mae: 4.203075328578867\n",
      "Current best mae: 4.183415402741942\n",
      "Current best mae: 4.1817797626139495\n",
      "Current best mae: 4.174373495455768\n",
      "Current best mae: 4.160921715100116\n",
      "Current best mae: 4.157436100586642\n",
      "Current best mae: 4.142808773866564\n",
      "Current best mae: 4.1378205501509395\n",
      "Current best mae: 4.130757069157309\n",
      "Current best mae: 4.123842491090669\n",
      "Current best mae: 4.121554123881426\n",
      "Current best mae: 4.095980229441419\n",
      "Current best mae: 4.094582064348404\n",
      "Current best mae: 4.082986136266474\n",
      "Current best mae: 4.064099480765821\n",
      "Current best mae: 4.059056360534554\n",
      "Current best mae: 4.05450800650762\n",
      "Current best mae: 4.0511804907787194\n",
      "Current best mae: 4.049230457726919\n",
      "Current best mae: 4.047030384890051\n",
      "Current best mae: 4.033168764305848\n",
      "Current best mae: 4.030783037172056\n",
      "Current best mae: 4.022953387644402\n",
      "Current best mae: 4.0202562547139955\n",
      "Current best mae: 4.0202519551850715\n",
      "Current best mae: 4.011341536982404\n",
      "Current best mae: 4.00719980763669\n",
      "Current best mae: 4.003394927334558\n",
      "Current best mae: 3.9973481199380303\n",
      "Current best mae: 3.996764992662505\n",
      "Current best mae: 3.9909695429369676\n",
      "Current best mae: 3.9873303301885676\n",
      "Current best mae: 3.987106842196559\n",
      "Current best mae: 3.9779831403694565\n",
      "Current best mae: 3.97548897108978\n",
      "Current best mae: 3.9710801930774964\n",
      "Current best mae: 3.968519900852921\n",
      "Current best mae: 3.960850315229257\n",
      "Current best mae: 3.959582977442184\n",
      "Current best mae: 3.9554925553873614\n",
      "Current best mae: 3.9536875294635743\n",
      "Current best mae: 3.9525237549624443\n",
      "Current best mae: 3.950382043054809\n",
      "Current best mae: 3.948806248731594\n",
      "Current best mae: 3.9471374823363505\n",
      "Current best mae: 3.946561161442721\n",
      "Current best mae: 3.9441914165699914\n",
      "Current best mae: 3.942648437267999\n",
      "Current best mae: 3.93925042273968\n",
      "Current best mae: 3.9347110878337745\n",
      "Current best mae: 3.9273293269731773\n",
      "Current best mae: 3.920301591481497\n",
      "Current best mae: 3.918212858133971\n",
      "Current best mae: 3.9132846637805434\n",
      "Current best mae: 3.91243105810224\n",
      "Current best mae: 3.909695220187269\n",
      "Current best mae: 3.909421736054078\n",
      "Current best mae: 3.907341042051732\n",
      "Current best mae: 3.9053875245138214\n",
      "Current best mae: 3.904743454460141\n",
      "Current best mae: 3.901974252933274\n",
      "Current best mae: 3.901428839513339\n",
      "Current best mae: 3.8996240918983722\n",
      "Current best mae: 3.899598706826474\n",
      "Current best mae: 3.8995974953541905\n",
      "Current best mae: 3.896498124463922\n",
      "Current best mae: 3.8869843848003107\n",
      "Current best mae: 3.8855399352086395\n",
      "Current best mae: 3.8836684844696436\n",
      "Current best mae: 3.8812839573382076\n",
      "Current best mae: 3.8805725389993007\n",
      "Current best mae: 3.8774053754420192\n",
      "Current best mae: 3.871217192342563\n",
      "Current best mae: 3.869599489524224\n",
      "Current best mae: 3.8665154578089465\n",
      "Current best mae: 3.862165129602542\n",
      "Current best mae: 3.8604231001459324\n",
      "Current best mae: 3.855874527509235\n",
      "Current best mae: 3.855832573632321\n",
      "Current best mae: 3.8544844419169926\n",
      "Current best mae: 3.8535127636047988\n",
      "Current best mae: 3.8532541092666266\n",
      "Current best mae: 3.8529644840490946\n",
      "Current best mae: 3.8484041080785945\n",
      "Current best mae: 3.8467196137193485\n",
      "Current best mae: 3.845246797806028\n",
      "Current best mae: 3.845043984060461\n",
      "Current best mae: 3.844001327527291\n",
      "Current best mae: 3.8415076581502623\n",
      "Current best mae: 3.841135065969733\n",
      "Current best mae: 3.8393233466541767\n",
      "Current best mae: 3.8389741860631403\n",
      "Current best mae: 3.838844658702004\n",
      "Current best mae: 3.8357503806602664\n",
      "Current best mae: 3.8343274295998504\n",
      "Current best mae: 3.833412168979301\n",
      "Current best mae: 3.832862285376714\n",
      "Current best mae: 3.831269059030002\n",
      "Current best mae: 3.830486562895067\n",
      "Current best mae: 3.83019789948849\n",
      "Current best mae: 3.8292327863850297\n",
      "Current best mae: 3.828693603071135\n",
      "Current best mae: 3.827653492827772\n",
      "Current best mae: 3.827068757527788\n",
      "Current best mae: 3.825523563096341\n",
      "Current best mae: 3.8246684567616165\n",
      "Current best mae: 3.8238226081533546\n",
      "Current best mae: 3.8230855949060696\n",
      "Current best mae: 3.8230770941410155\n",
      "Current best mae: 3.822512923727975\n",
      "Current best mae: 3.8195614737757766\n",
      "Current best mae: 3.8180726655309143\n",
      "Current best mae: 3.816339024648707\n",
      "Current best mae: 3.8156395069600926\n",
      "Current best mae: 3.8145379674651343\n",
      "Current best mae: 3.814143245533434\n",
      "Current best mae: 3.810073976788837\n",
      "Current best mae: 3.8090654706473197\n",
      "Current best mae: 3.808945717605225\n",
      "Current best mae: 3.808631624474623\n",
      "Current best mae: 3.8085356156384966\n",
      "Current best mae: 3.806780158868046\n",
      "Current best mae: 3.8048428941277592\n",
      "Current best mae: 3.802614362435204\n",
      "Current best mae: 3.801514556165146\n",
      "Current best mae: 3.8014909360814406\n",
      "Current best mae: 3.8006533726996565\n",
      "Current best mae: 3.7997703524756057\n",
      "Current best mae: 3.7985010785431044\n",
      "Current best mae: 3.7978124394474704\n",
      "Current best mae: 3.7975886024234775\n",
      "Current best mae: 3.796681558186672\n",
      "Current best mae: 3.7964307343114596\n",
      "Current best mae: 3.7962934726930313\n",
      "Current best mae: 3.7943243937775053\n",
      "Current best mae: 3.793501113555341\n",
      "Current best mae: 3.7933790251753168\n",
      "Current best mae: 3.792543950263358\n",
      "Current best mae: 3.7923536624361476\n",
      "Current best mae: 3.7923494944673735\n",
      "Current best mae: 3.789236181790739\n",
      "Current best mae: 3.788974827715356\n",
      "Current best mae: 3.7877567781543435\n",
      "Current best mae: 3.7875235052171563\n",
      "Current best mae: 3.7874667727531035\n",
      "Current best mae: 3.7866609798804562\n",
      "Current best mae: 3.7862463205207204\n",
      "Current best mae: 3.785856026848888\n",
      "Current best mae: 3.784460207817477\n",
      "Current best mae: 3.7844015213401136\n",
      "Current best mae: 3.784304216528304\n",
      "Current best mae: 3.78289579394757\n",
      "Current best mae: 3.782703037507151\n",
      "Current best mae: 3.781915280432622\n",
      "Current best mae: 3.7817502227481627\n",
      "Current best mae: 3.781398575708476\n",
      "Current best mae: 3.7810956479225646\n",
      "Current best mae: 3.7810821023950383\n",
      "Current best mae: 3.7809367277907846\n",
      "Current best mae: 3.7806809498489975\n",
      "Current best mae: 3.780079963448794\n",
      "Current best mae: 3.77927891069334\n",
      "Current best mae: 3.7790588025587963\n",
      "Current best mae: 3.778575091957305\n",
      "Current best mae: 3.778562767427508\n",
      "Current best mae: 3.777355352555624\n",
      "Current best mae: 3.77691628830409\n",
      "Current best mae: 3.7768965100385827\n",
      "Current best mae: 3.7765582418955446\n",
      "Current best mae: 3.774450170933041\n",
      "Current best mae: 3.774143968448019\n",
      "Current best mae: 3.7738153273101354\n",
      "Current best mae: 3.7730897127863408\n",
      "Current best mae: 3.772836435565092\n",
      "Current best mae: 3.772500274030005\n",
      "Current best mae: 3.7720166291701345\n",
      "Current best mae: 3.7715997298724653\n",
      "Current best mae: 3.771266511962183\n",
      "Current best mae: 3.770712860476351\n",
      "Current best mae: 3.770282319741658\n",
      "Current best mae: 3.7701725861066975\n",
      "Current best mae: 3.769403148195495\n",
      "Current best mae: 3.7693386011190966\n",
      "Current best mae: 3.7688109113089503\n",
      "Current best mae: 3.767881944710401\n",
      "Current best mae: 3.7678642300780174\n",
      "Current best mae: 3.7676046855363623\n",
      "Current best mae: 3.7670709681428365\n",
      "Current best mae: 3.767005692592383\n",
      "Current best mae: 3.766813047306303\n",
      "Current best mae: 3.7666268894430877\n",
      "Current best mae: 3.766250281109228\n",
      "Current best mae: 3.766160964225888\n",
      "Current best mae: 3.7655586474232208\n",
      "Current best mae: 3.7653171657734648\n",
      "Current best mae: 3.7651444525543654\n",
      "Current best mae: 3.7651339348823973\n",
      "Current best mae: 3.7649790182802336\n",
      "Current best mae: 3.7647784532883426\n",
      "Current best mae: 3.764714530202499\n",
      "Final best mae 3.764714530202499\n"
     ]
    }
   ],
   "source": [
    "# PSO test!\n",
    "import pso\n",
    "\n",
    "swarmsize = 100\n",
    "alpha = 0.7\n",
    "beta = 2\n",
    "gamma = 1.5\n",
    "delta = 1.5\n",
    "epsilon = 0.4\n",
    "n_iter = 100\n",
    "\n",
    "particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=True)\n",
    "opti_particle, best_mae_arr = particle_swarm_opti.optimise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potential ranges of PSO parameters to try\n",
    "# Could try them like a gridsearch but its probably a bit too much for that, tuning one at a time is probably the way to go\n",
    "\n",
    "alphaRange = np.arange(0.4,0.9,0.1)\n",
    "betaRange = np.arange(1.5,2.5,0.1)\n",
    "gammaRange = np.arange(1.5,2.5,0.1)\n",
    "deltaRange = np.arange(1.5,2.5,0.1)\n",
    "epsilonRange = np.arange(0.1,0.5,0.1) # not sure about the range of the learning rate, might need to experiment or look for more sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha tuning\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for alpha in alphaRange:\n",
    "    network = neuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try neural network architectures\n",
    "# 2-10 layers\n",
    "# 3-10 neurons per layer\n",
    "\n",
    "layers = range(1, 5) # 1 to x hidden layer\n",
    "#neurons = range(2, 30) # 2 to 30 neurons\n",
    "# Try different layers\n",
    "# Constant 4 neurons per layer, activation func relu\n",
    "\n",
    "accuraciesForLayers = []\n",
    "for numLayers in layers:\n",
    "    network = neuralNet()\n",
    "    network.add(layer(ActFunc.hb,4))\n",
    "    for i in range(numLayers - 1):\n",
    "        network.add(layer(ActFunc.relu,4))\n",
    "    network.add(layer(ActFunc.relu, 1)) # output layer\n",
    "    layerTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter,prints=False)\n",
    "    opti_particle, best_mae_arr = layerTestPSO.optimise()\n",
    "    accuraciesForLayers.append(best_mae_arr[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.555264950844917, 8.99807228712115, 7.945903903327652, 9.003288963387677]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuraciesForLayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m network\u001b[38;5;241m.\u001b[39madd(layer(ActFunc\u001b[38;5;241m.\u001b[39mrelu,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     11\u001b[0m neuronsTestPSO \u001b[38;5;241m=\u001b[39m pso\u001b[38;5;241m.\u001b[39mPSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter,prints\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 12\u001b[0m opti_particle, best_mae_arr \u001b[38;5;241m=\u001b[39m neuronsTestPSO\u001b[38;5;241m.\u001b[39moptimise()\n\u001b[0;32m     13\u001b[0m accuraciesForNeuronCounts\u001b[38;5;241m.\u001b[39mappend(best_mae_arr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\chany\\OneDrive\\Desktop\\Academic\\MSc\\Biological Inspired Computing\\CW\\pso.py:138\u001b[0m, in \u001b[0;36mPSO.optimise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m x_star \u001b[38;5;241m=\u001b[39m particle\u001b[38;5;241m.\u001b[39mprevBest\n\u001b[0;32m    137\u001b[0m x_plus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfittestLoc(particle\u001b[38;5;241m.\u001b[39minformant)\n\u001b[1;32m--> 138\u001b[0m x_prime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfittestLoc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparticles)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# Do the change velo\u001b[39;00m\n\u001b[0;32m    141\u001b[0m particle\u001b[38;5;241m.\u001b[39mchangeVelo(particle\u001b[38;5;241m.\u001b[39mpos, x_star, x_plus, x_prime)\n",
      "File \u001b[1;32mc:\\Users\\chany\\OneDrive\\Desktop\\Academic\\MSc\\Biological Inspired Computing\\CW\\pso.py:54\u001b[0m, in \u001b[0;36mPSO.fittestLoc\u001b[1;34m(self, someParticles)\u001b[0m\n\u001b[0;32m     52\u001b[0m fittest_mae \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m someParticles:\n\u001b[1;32m---> 54\u001b[0m     mae \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massessFitness(p\u001b[38;5;241m.\u001b[39mpos, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my)\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fittest_mae \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m mae \u001b[38;5;241m<\u001b[39m fittest_mae:\n\u001b[0;32m     56\u001b[0m         fittest_mae \u001b[38;5;241m=\u001b[39m mae\n",
      "File \u001b[1;32mc:\\Users\\chany\\OneDrive\\Desktop\\Academic\\MSc\\Biological Inspired Computing\\CW\\pso.py:89\u001b[0m, in \u001b[0;36mPSO.assessFitness\u001b[1;34m(self, pos, y)\u001b[0m\n\u001b[0;32m     85\u001b[0m weights_arr, bias_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massessFitness_helper(pos)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Calculate the pred y\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m yhat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mforwardCalculation, args \u001b[38;5;241m=\u001b[39m (weights_arr, bias_arr), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# print(self.X.iloc[0])\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# print(self.X.iloc[1])\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# print(\"First\", self.network.forwardCalculation(self.X.iloc[0], weights_arr, bias_arr))\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# print(\"Second\", self.network.forwardCalculation(self.X.iloc[1], weights_arr, bias_arr))\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m#print(\"yhat:\\n\", yhat)\u001b[39;00m\n\u001b[0;32m     95\u001b[0m mae \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39merrorCalculation(yhat, y)\n",
      "File \u001b[1;32mc:\\Users\\chany\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\chany\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\chany\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\chany\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\chany\\OneDrive\\Desktop\\Academic\\MSc\\Biological Inspired Computing\\CW\\neuralNet.py:14\u001b[0m, in \u001b[0;36mneuralNet.forwardCalculation\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m     12\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 14\u001b[0m     output \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mlayerCalculation(\u001b[38;5;28minput\u001b[39m, weight[i], bias[i])\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# print(\"input\", input)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m output\n",
      "File \u001b[1;32mc:\\Users\\chany\\OneDrive\\Desktop\\Academic\\MSc\\Biological Inspired Computing\\CW\\layer.py:33\u001b[0m, in \u001b[0;36mlayer.layerCalculation\u001b[1;34m(self, inputs, weights, bias)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# initialize all weights as 1 in case we do not have any specified\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# it is now an 2D array, lists containing weights for a single neuron (one weight for each input) grouped into a list (one list of weights for every neuron)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# if weights == None:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# if bias == None:\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#     self.bias = [1] * len(self.perceptronArr)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, perc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperceptronArr):\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput[i] \u001b[38;5;241m=\u001b[39m perc\u001b[38;5;241m.\u001b[39mCalculateOutput(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[i], \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39minputs, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias[i])\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\n",
      "File \u001b[1;32mc:\\Users\\chany\\OneDrive\\Desktop\\Academic\\MSc\\Biological Inspired Computing\\CW\\perceptron.py:12\u001b[0m, in \u001b[0;36mPerceptron.CalculateOutput\u001b[1;34m(self, weights, input, bias)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mCalculateOutput\u001b[39m(\u001b[38;5;28mself\u001b[39m, weights, \u001b[38;5;28minput\u001b[39m, bias):\n\u001b[1;32m---> 12\u001b[0m     z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28minput\u001b[39m)\u001b[38;5;241m.\u001b[39mT,np\u001b[38;5;241m.\u001b[39marray(weights)) \u001b[38;5;241m+\u001b[39m bias\n\u001b[0;32m     13\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivationFunc(z)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m s\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "neurons = range(3,11)\n",
    "\n",
    "accuraciesForNeuronCounts = []\n",
    "\n",
    "for neuronCount in neurons:\n",
    "    network = neuralNet()\n",
    "    network.add(layer(ActFunc.hb,neuronCount))\n",
    "    for i in range(4):\n",
    "        network.add(layer(ActFunc.relu,neuronCount))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    neuronsTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter,prints=False)\n",
    "    opti_particle, best_mae_arr = neuronsTestPSO.optimise()\n",
    "    accuraciesForNeuronCounts.append(best_mae_arr[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.77999457152216,\n",
       " 12.72358284385077,\n",
       " 12.7507459293109,\n",
       " 12.128013690751219,\n",
       " 12.719167595808477,\n",
       " 12.824716139342142,\n",
       " 12.408683654740194,\n",
       " 12.857943071520861]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuraciesForNeuronCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current best mae: 35.85259317964667\n",
      "Current best mae: 34.69681357489294\n",
      "Current best mae: 34.57583386548679\n",
      "Current best mae: 34.528113056444205\n",
      "Current best mae: 34.45672812841521\n",
      "Current best mae: 34.41090745672881\n",
      "Current best mae: 34.324431491120244\n",
      "Current best mae: 34.294726777641266\n",
      "Current best mae: 34.28983005576441\n",
      "Current best mae: 34.193372938226794\n",
      "Current best mae: 34.05013041346951\n",
      "Current best mae: 33.98174222565102\n",
      "Current best mae: 33.962905969409114\n",
      "Current best mae: 33.803408176990864\n",
      "Current best mae: 33.74312486513459\n",
      "Final best mae 33.74312486513459\n",
      "Current best mae: 36.02132686084143\n",
      "Current best mae: 34.86166751582179\n",
      "Current best mae: 34.71753830103664\n",
      "Current best mae: 33.145525777035196\n",
      "Current best mae: 30.782203153340518\n",
      "Current best mae: 30.385000898299694\n",
      "Current best mae: 27.099677806233892\n",
      "Current best mae: 25.250007834601348\n",
      "Current best mae: 24.461610627611773\n",
      "Current best mae: 21.39562300399524\n",
      "Current best mae: 19.69661966269415\n",
      "Current best mae: 19.028058550005618\n",
      "Current best mae: 18.007113608215757\n",
      "Current best mae: 15.444927069646296\n",
      "Current best mae: 15.174603548973094\n",
      "Current best mae: 13.713385009675592\n",
      "Current best mae: 13.575783640511792\n",
      "Current best mae: 12.91488081133865\n",
      "Current best mae: 12.889661693950325\n",
      "Current best mae: 12.741064236340511\n",
      "Current best mae: 12.54237267136042\n",
      "Final best mae 12.54237267136042\n",
      "Current best mae: 35.713306820642714\n",
      "Current best mae: 35.10923856095976\n",
      "Current best mae: 34.72307628155625\n",
      "Current best mae: 33.936092805426114\n",
      "Current best mae: 33.79608163070153\n",
      "Current best mae: 33.55657460084316\n",
      "Current best mae: 31.190949053910373\n",
      "Current best mae: 29.893697433503743\n",
      "Current best mae: 28.19356451088987\n",
      "Current best mae: 27.074481352994734\n",
      "Current best mae: 24.969073076928883\n",
      "Current best mae: 21.496358587887176\n",
      "Current best mae: 18.05116895529437\n",
      "Current best mae: 16.648835092007182\n",
      "Current best mae: 16.143613254949646\n",
      "Current best mae: 12.722248391920347\n",
      "Final best mae 12.722248391920347\n",
      "Current best mae: 36.02132686084143\n",
      "Current best mae: 35.5515933513081\n",
      "Current best mae: 35.05186579316225\n",
      "Current best mae: 34.99173084033626\n",
      "Current best mae: 34.54941931248526\n",
      "Current best mae: 33.83629503823278\n",
      "Current best mae: 30.64486174069995\n",
      "Current best mae: 12.092755727836616\n",
      "Final best mae 12.092755727836616\n",
      "Current best mae: 36.02132686084143\n",
      "Current best mae: 35.765658905373215\n",
      "Current best mae: 34.862755018964044\n",
      "Current best mae: 34.628498905589915\n",
      "Current best mae: 32.61902540292494\n",
      "Current best mae: 28.631198190001463\n",
      "Current best mae: 13.68065786044105\n",
      "Current best mae: 12.827363130350998\n",
      "Current best mae: 12.31138965117577\n",
      "Final best mae 12.31138965117577\n"
     ]
    }
   ],
   "source": [
    "accuraciesForAlphas = []\n",
    "\n",
    "for a in alphaRange:\n",
    "    network = neuralNet()\n",
    "    network.add(layer(ActFunc.relu, 32))\n",
    "    network.add(layer(ActFunc.hb, 64))\n",
    "    network.add(layer(ActFunc.log, 128))\n",
    "    network.add(layer(ActFunc.relu, 1))\n",
    "    alphaTestPSO = pso.PSO(X_train, y_train, network, swarmsize, a, beta, gamma, delta, epsilon, n_iter,prints=True)\n",
    "    opti_particle, best_mae_arr = alphaTestPSO.optimise()\n",
    "    accuraciesForAlphas.append(best_mae_arr[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuraciesForBetas = []\n",
    "\n",
    "for b in betaRange:\n",
    "    network = neuralNet()\n",
    "    network.add(layer(ActFunc.relu, 32))\n",
    "    network.add(layer(ActFunc.hb, 64))\n",
    "    network.add(layer(ActFunc.log, 128))\n",
    "    network.add(layer(ActFunc.relu, 1))\n",
    "    betaTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, b, gamma, delta, epsilon, n_iter,prints=False)\n",
    "    opti_particle, best_mae_arr = betaTestPSO.optimise()\n",
    "    accuraciesForBetas.append(best_mae_arr[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current best mae: 35.03732489082014\n",
      "Current best mae: 34.83481894686642\n",
      "Current best mae: 34.745755447373725\n",
      "Current best mae: 34.64531044922929\n",
      "Current best mae: 34.60332779781707\n",
      "Current best mae: 32.710327530758406\n",
      "Current best mae: 28.820975490880095\n",
      "Current best mae: 23.239086160809002\n",
      "Current best mae: 23.07334211113402\n",
      "Current best mae: 21.859346951976192\n",
      "Current best mae: 16.771328334107093\n",
      "Current best mae: 14.049072244543881\n",
      "Current best mae: 13.343404478554394\n",
      "Current best mae: 12.827673060536709\n",
      "Current best mae: 12.680568295327712\n",
      "Final best mae 12.680568295327712\n",
      "Current best mae: 36.02132686084143\n",
      "Current best mae: 35.51584165507827\n",
      "Current best mae: 34.94048970391011\n",
      "Current best mae: 33.561521441650186\n",
      "Current best mae: 33.20769068142707\n",
      "Current best mae: 32.314306604952115\n",
      "Current best mae: 27.684011543484573\n",
      "Current best mae: 22.974407913667832\n",
      "Current best mae: 21.822743236811984\n",
      "Current best mae: 20.92016318451177\n",
      "Current best mae: 20.244727407852054\n",
      "Current best mae: 13.508776872632865\n",
      "Current best mae: 12.744009937028428\n",
      "Final best mae 12.744009937028428\n",
      "Current best mae: 35.411450255385994\n",
      "Current best mae: 35.14688826284203\n",
      "Current best mae: 34.60724161637674\n",
      "Current best mae: 33.91495713704345\n",
      "Current best mae: 33.82354849941957\n",
      "Current best mae: 30.451890106224546\n",
      "Current best mae: 27.05255446876598\n",
      "Current best mae: 13.838620046543044\n",
      "Current best mae: 13.585759597115823\n",
      "Current best mae: 12.722592091254265\n",
      "Final best mae 12.722592091254265\n",
      "Current best mae: 35.5363899598279\n",
      "Current best mae: 33.94291719858055\n",
      "Current best mae: 17.029736207425085\n",
      "Current best mae: 12.779353617125837\n",
      "Current best mae: 12.506620477752872\n",
      "Final best mae 12.506620477752872\n",
      "Current best mae: 36.02132686084143\n",
      "Current best mae: 35.661628534865066\n",
      "Current best mae: 35.52790240432713\n",
      "Current best mae: 35.37449141754508\n",
      "Current best mae: 34.82332679529155\n",
      "Current best mae: 34.45956346692133\n",
      "Current best mae: 33.21155712636742\n",
      "Current best mae: 32.326682079726325\n",
      "Current best mae: 31.55778940354174\n",
      "Current best mae: 31.456902800771275\n",
      "Current best mae: 20.616831796820737\n",
      "Current best mae: 20.07283377513576\n",
      "Current best mae: 13.772414750538854\n",
      "Current best mae: 12.971796823022851\n",
      "Final best mae 12.971796823022851\n",
      "Current best mae: 35.13957024462608\n",
      "Current best mae: 33.51864754425366\n",
      "Current best mae: 30.430234527136516\n",
      "Current best mae: 23.86112040233781\n",
      "Current best mae: 21.52522288873148\n",
      "Current best mae: 15.38972556610239\n",
      "Current best mae: 14.61064368204456\n",
      "Current best mae: 13.13628460753873\n",
      "Current best mae: 13.117467239323854\n",
      "Final best mae 13.117467239323854\n",
      "Current best mae: 36.02132686084143\n",
      "Current best mae: 31.567638387469557\n",
      "Current best mae: 27.428345732770815\n"
     ]
    }
   ],
   "source": [
    "accuraciesForGammas = []\n",
    "\n",
    "for g in gammaRange:\n",
    "    network = neuralNet()\n",
    "    network.add(layer(ActFunc.relu, 32))\n",
    "    network.add(layer(ActFunc.hb, 64))\n",
    "    network.add(layer(ActFunc.log, 128))\n",
    "    network.add(layer(ActFunc.relu, 1))\n",
    "    gammaTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, g, delta, epsilon, n_iter,prints=True)\n",
    "    opti_particle, best_mae_arr = gammaTestPSO.optimise()\n",
    "    accuraciesForGammas.append(best_mae_arr[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuraciesForDeltas = []\n",
    "\n",
    "for d in deltaRange:\n",
    "    network = neuralNet()\n",
    "    network.add(layer(ActFunc.relu, 32))\n",
    "    network.add(layer(ActFunc.hb, 64))\n",
    "    network.add(layer(ActFunc.log, 128))\n",
    "    network.add(layer(ActFunc.relu, 1))\n",
    "    deltaTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, d, epsilon, n_iter,prints=False)\n",
    "    opti_particle, best_mae_arr = deltaTestPSO.optimise()\n",
    "    accuraciesForDeltas.append(best_mae_arr[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuraciesForEpsilons = []\n",
    "\n",
    "for e in epsilonRange:\n",
    "    network = neuralNet()\n",
    "    network.add(layer(ActFunc.relu, 32))\n",
    "    network.add(layer(ActFunc.hb, 64))\n",
    "    network.add(layer(ActFunc.log, 128))\n",
    "    network.add(layer(ActFunc.relu, 1))\n",
    "    epsilonTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, e, n_iter,prints=False)\n",
    "    opti_particle, best_mae_arr = epsilonTestPSO.optimise()\n",
    "    accuraciesForEpsilons.append(best_mae_arr[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16.420837013206647,\n",
       " 12.720444335810935,\n",
       " 12.718655332856695,\n",
       " 12.722071306269948,\n",
       " 12.719791479367064]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuraciesForAlphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuraciesForBetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.912423059242027,\n",
       " 12.607260914762906,\n",
       " 12.718739317776018,\n",
       " 14.180441401854601,\n",
       " 13.854707487624232,\n",
       " 13.506649285547871,\n",
       " 36.02132686084143,\n",
       " 13.11766997924925,\n",
       " 36.02132686084143,\n",
       " 36.02132686084143]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuraciesForGammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuraciesForDeltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuraciesForEpsilons"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
