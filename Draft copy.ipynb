{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Multi-layer ANN\n",
    "\n",
    "Hyperparameters:\n",
    " 1. Number of nodes\n",
    " 2. Number of layers\n",
    " 3. Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from enum import Enum\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>blast_furnace_slag</th>\n",
       "      <th>fly_ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>coarse_aggregate</th>\n",
       "      <th>fine_aggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>concrete_compressive_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement  blast_furnace_slag  fly_ash  water  superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   coarse_aggregate  fine_aggregate   age  concrete_compressive_strength  \n",
       "0            1040.0            676.0   28                          79.99  \n",
       "1            1055.0            676.0   28                          61.89  \n",
       "2             932.0            594.0  270                          40.27  \n",
       "3             932.0            594.0  365                          41.05  \n",
       "4             978.4            825.5  360                          44.30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "concrete = pd.read_csv('data/concrete_data.csv')\n",
    "concrete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X and Y\n",
    "# Then separate test and train set\n",
    "# Also do the Cross-Validation (optional)\n",
    "X = concrete.drop('concrete_compressive_strength', axis = 1)\n",
    "y = concrete['concrete_compressive_strength']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.7, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function\n",
    "def logistic(x):\n",
    "    return 1/(1 + math.exp(-x))\n",
    "\n",
    "def ReLU(x):\n",
    "    return max(0, x)\n",
    "\n",
    "def hyperbolic(x):\n",
    "    return math.tanh(x)\n",
    "\n",
    "class ActFunc(Enum):\n",
    "    log = logistic\n",
    "    relu = ReLU\n",
    "    hb = hyperbolic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network test!\n",
    "from neuralNet import neuralNet\n",
    "from layer import layer\n",
    "\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,6))\n",
    "network.add(layer(ActFunc.relu,4))\n",
    "network.add(layer(ActFunc.relu,2))\n",
    "network.add(layer(ActFunc.relu,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Implement the PSO\n",
    "\n",
    "Hyperparameters:\n",
    "1. Swarmsize\n",
    "2. Alpha\n",
    "3. Beta\n",
    "4. Gamma\n",
    "5. Delta\n",
    "6. Epsilon\n",
    "7. Number of iterations (epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.451531634425892"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PSO test!\n",
    "import pso\n",
    "\n",
    "swarmsize = 10\n",
    "alpha = 0.7\n",
    "beta = 2\n",
    "gamma = 1.5\n",
    "delta = 1.5\n",
    "epsilon = 0.4\n",
    "n_iter = 10\n",
    "\n",
    "all_best = []\n",
    "for i in range(1):\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "    all_best.append(best_mae_arr[-1])\n",
    "avg_best = sum(all_best)/len(all_best)\n",
    "avg_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3, 4 & 5: Exploring ANN and PSO hyperparameters on the concrete data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying different number of layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 10.14732421201561,\n",
       " 3: 15.004473812005005,\n",
       " 4: 16.387779330618713,\n",
       " 5: 11.385846704402498,\n",
       " 6: 11.484367661039272,\n",
       " 7: 12.772960385320248,\n",
       " 8: 13.45855669636377,\n",
       " 9: 18.403413570468995}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try neural network architectures\n",
    "# 2-10 layers\n",
    "# 3-10 neurons per layer\n",
    "\n",
    "layers = range(2,10)\n",
    "\n",
    "# Try different layers\n",
    "# Constant 4 neurons per layer, activation func relu\n",
    "\n",
    "avg_accuraciesForLayers = {}\n",
    "for numLayers in layers:\n",
    "    accuraciesForLayers = []\n",
    "    # Set up network\n",
    "    network = neuralNet()\n",
    "    for i in range(numLayers - 1):\n",
    "        network.add(layer(ActFunc.relu,4))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    for i in range(1):\n",
    "        layerTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter,prints=False)\n",
    "        opti_particle, best_mae_arr = layerTestPSO.optimise()\n",
    "        accuraciesForLayers.append(best_mae_arr[-1])\n",
    "    avg_accuraciesForLayers[numLayers] = sum(accuraciesForLayers)/len(accuraciesForLayers)\n",
    "avg_accuraciesForLayers\n",
    "\n",
    "# Best: 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 10.14732421201561,\n",
       " 3: 15.004473812005005,\n",
       " 4: 16.387779330618713,\n",
       " 5: 11.385846704402498,\n",
       " 6: 11.484367661039272,\n",
       " 7: 12.772960385320248,\n",
       " 8: 13.45855669636377,\n",
       " 9: 18.403413570468995}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuraciesForLayers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying different number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 12.21494578778015,\n",
       " 3: 12.257277960554257,\n",
       " 4: 15.226750719901235,\n",
       " 5: 12.645783111308017,\n",
       " 6: 15.028134405611029,\n",
       " 7: 26.95547406706671,\n",
       " 8: 11.907367701166727,\n",
       " 9: 14.072182658966591,\n",
       " 10: 14.602080711399982}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons = range(2,11)\n",
    "\n",
    "avg_accuraciesForNeuronCounts = {}\n",
    "\n",
    "for neuronCount in neurons:\n",
    "    accuraciesForNeuronCounts = []\n",
    "    # Set up network\n",
    "    network = neuralNet()\n",
    "    for i in range(3):\n",
    "        network.add(layer(ActFunc.relu,neuronCount))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    # Run optimisation 10 times\n",
    "    for i in range(1):\n",
    "        neuronsTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter,prints=False)\n",
    "        opti_particle, best_mae_arr = neuronsTestPSO.optimise()\n",
    "        accuraciesForNeuronCounts.append(best_mae_arr[-1])\n",
    "    avg_accuraciesForNeuronCounts[neuronCount] = sum(accuraciesForNeuronCounts)/len(accuraciesForNeuronCounts)\n",
    "avg_accuraciesForNeuronCounts\n",
    "\n",
    "# Best is 3 neurons per layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 12.21494578778015,\n",
       " 3: 12.257277960554257,\n",
       " 4: 15.226750719901235,\n",
       " 5: 12.645783111308017,\n",
       " 6: 15.028134405611029,\n",
       " 7: 26.95547406706671,\n",
       " 8: 11.907367701166727,\n",
       " 9: 14.072182658966591,\n",
       " 10: 14.602080711399982}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuraciesForNeuronCounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSO hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potential ranges of PSO parameters to try\n",
    "# Could try them like a gridsearch but its probably a bit too much for that, tuning one at a time is probably the way to go\n",
    "\n",
    "alphaRange = np.arange(0.4,0.9,0.1)\n",
    "betaRange = np.arange(1.5,2.5,0.1)\n",
    "gammaRange = np.arange(1.5,2.5,0.1)\n",
    "deltaRange = np.arange(1.5,2.5,0.1)\n",
    "epsilonRange = np.arange(0.1,0.5,0.1) # not sure about the range of the learning rate, might need to experiment or look for more sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuraciesForAlphas = {}\n",
    "\n",
    "for a in alphaRange:\n",
    "    accuraciesForAlphas = []\n",
    "    # Set up network\n",
    "    network = neuralNet()\n",
    "    for i in range(3):\n",
    "        network.add(layer(ActFunc.relu,3))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    for i in range(1):\n",
    "        alphaTestPSO = pso.PSO(X_train, y_train, network, swarmsize, a, beta, gamma, delta, epsilon, n_iter,prints=False)\n",
    "        opti_particle, best_mae_arr = alphaTestPSO.optimise()\n",
    "        accuraciesForAlphas.append(best_mae_arr[-1])\n",
    "    avg_accuraciesForAlphas[a] = sum(accuraciesForAlphas)/len(accuraciesForAlphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuraciesForBetas = {}\n",
    "\n",
    "for b in betaRange:\n",
    "    accuraciesForBetas = []\n",
    "    # Set up network\n",
    "    network = neuralNet()\n",
    "    for i in range(3):\n",
    "        network.add(layer(ActFunc.relu,3))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    for i in range(1):\n",
    "        betaTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, b, gamma, delta, epsilon, n_iter,prints=False)\n",
    "        opti_particle, best_mae_arr = betaTestPSO.optimise()\n",
    "        accuraciesForBetas.append(best_mae_arr[-1])\n",
    "    avg_accuraciesForBetas[b] = sum(accuraciesForBetas)/len(accuraciesForBetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuraciesForGammas = {}\n",
    "\n",
    "for g in gammaRange:\n",
    "    accuraciesForGammas = []\n",
    "    # Set up network\n",
    "    network = neuralNet()\n",
    "    for i in range(3):\n",
    "        network.add(layer(ActFunc.relu,3))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    for i in range(1):\n",
    "        gammaTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, g, delta, epsilon, n_iter,prints=False)\n",
    "        opti_particle, best_mae_arr = gammaTestPSO.optimise()\n",
    "        accuraciesForGammas.append(best_mae_arr[-1])\n",
    "    avg_accuraciesForGammas[g] = sum(accuraciesForGammas)/len(accuraciesForGammas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuraciesForDeltas = {}\n",
    "\n",
    "for d in deltaRange:\n",
    "    accuraciesForDeltas = []\n",
    "    # Set up network\n",
    "    network = neuralNet()\n",
    "    for i in range(3):\n",
    "        network.add(layer(ActFunc.relu,3))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    for i in range(1):\n",
    "        deltaTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, d, epsilon, n_iter,prints=False)\n",
    "        opti_particle, best_mae_arr = deltaTestPSO.optimise()\n",
    "        accuraciesForDeltas.append(best_mae_arr[-1])\n",
    "    avg_accuraciesForDeltas[d] = sum(accuraciesForDeltas)/len(accuraciesForDeltas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuraciesForEpsilons = {}\n",
    "\n",
    "for e in epsilonRange:\n",
    "    accuraciesForEpsilons = []\n",
    "\n",
    "    # Set up network\n",
    "    network = neuralNet()\n",
    "    for i in range(3):\n",
    "        network.add(layer(ActFunc.relu,3))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    for i in range(1):\n",
    "        epsilonTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, e, n_iter,prints=False)\n",
    "        opti_particle, best_mae_arr = epsilonTestPSO.optimise()\n",
    "        accuraciesForEpsilons.append(best_mae_arr[-1])\n",
    "    avg_accuraciesForEpsilons[e] = sum(accuraciesForEpsilons)/len(accuraciesForEpsilons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.float64(0.4): 15.065149086931363,\n",
       " np.float64(0.5): 12.711912078193958,\n",
       " np.float64(0.6): 11.89618211308327,\n",
       " np.float64(0.7): 12.692801781346283,\n",
       " np.float64(0.7999999999999999): 13.67870935308151}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuraciesForAlphas \n",
    "# Best: 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.float64(1.5): 30.325597484110258,\n",
       " np.float64(1.6): 11.809658675068352,\n",
       " np.float64(1.7000000000000002): 15.78216376104455,\n",
       " np.float64(1.8000000000000003): 13.286233181558115,\n",
       " np.float64(1.9000000000000004): 12.72433392654653,\n",
       " np.float64(2.0000000000000004): 14.577975466970747,\n",
       " np.float64(2.1000000000000005): 12.347327592841335,\n",
       " np.float64(2.2000000000000006): 13.273909090656577,\n",
       " np.float64(2.3000000000000007): 13.114383455940429,\n",
       " np.float64(2.400000000000001): 15.8696925774791}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuraciesForBetas\n",
    "# Best: 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.float64(1.5): 16.571768133035697,\n",
       " np.float64(1.6): 12.64076288542907,\n",
       " np.float64(1.7000000000000002): 14.717056640649119,\n",
       " np.float64(1.8000000000000003): 13.792139508456104,\n",
       " np.float64(1.9000000000000004): 12.004093797385174,\n",
       " np.float64(2.0000000000000004): 13.721067600981334,\n",
       " np.float64(2.1000000000000005): 13.60463294924608,\n",
       " np.float64(2.2000000000000006): 16.888981482950182,\n",
       " np.float64(2.3000000000000007): 11.53568424795468,\n",
       " np.float64(2.400000000000001): 12.97534767568286}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuraciesForGammas\n",
    "# Best: 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.float64(1.5): 11.88655941687413,\n",
       " np.float64(1.6): 13.394002432529403,\n",
       " np.float64(1.7000000000000002): 14.502812570138076,\n",
       " np.float64(1.8000000000000003): 12.274850526547047,\n",
       " np.float64(1.9000000000000004): 12.38548413089067,\n",
       " np.float64(2.0000000000000004): 15.249815404253688,\n",
       " np.float64(2.1000000000000005): 12.840889574482826,\n",
       " np.float64(2.2000000000000006): 13.738451861644485,\n",
       " np.float64(2.3000000000000007): 15.305001339880624,\n",
       " np.float64(2.400000000000001): 15.683789970039138}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuraciesForDeltas\n",
    "# Best: 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.float64(0.1): 13.060614984879418,\n",
       " np.float64(0.2): 16.751982422083433,\n",
       " np.float64(0.30000000000000004): 12.405030990844962,\n",
       " np.float64(0.4): 14.761597759012353}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuraciesForEpsilons\n",
    "# Best: 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few best combination of hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.677595506562039"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combination 1\n",
    "# Network layer (3, 3, 3)\n",
    "# All best PSO hyperparam\n",
    "\n",
    "# Set up network\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,1))\n",
    "\n",
    "# PSO Hyperparams\n",
    "swarmsize = 10\n",
    "alpha = 0.6\n",
    "beta = 2.4\n",
    "gamma = 1.5\n",
    "delta = 1.6\n",
    "epsilon = 0.4\n",
    "n_iter = 10\n",
    "\n",
    "mse_arr = []\n",
    "for i in range(10):\n",
    "    # Getting optimal position\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "\n",
    "    # Apply to test set\n",
    "    weights, bias = particle_swarm_opti.assessFitness_helper( opti_particle)\n",
    "    y_pred = X_test.apply(network.forwardCalculation, args = (weights, bias), axis = 1)\n",
    "    mse_arr.append(network.errorCalculation(y_pred, y_test))\n",
    "mse_comb1 = sum(mse_arr)/len(mse_arr)\n",
    "mse_comb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.666496699815912"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combination 2\n",
    "# Network layer (6, 4, 2)\n",
    "# All best PSO hyperparam\n",
    "\n",
    "# Set up network\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,6))\n",
    "network.add(layer(ActFunc.relu,4))\n",
    "network.add(layer(ActFunc.relu,2))\n",
    "network.add(layer(ActFunc.relu,1))\n",
    "\n",
    "# PSO Hyperparams\n",
    "swarmsize = 10\n",
    "alpha = 0.6\n",
    "beta = 2.4\n",
    "gamma = 1.5\n",
    "delta = 1.6\n",
    "epsilon = 0.4\n",
    "n_iter = 10\n",
    "\n",
    "mse_arr = []\n",
    "for i in range(10):\n",
    "    # Getting optimal position\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "\n",
    "    # Apply to test set\n",
    "    weights, bias = particle_swarm_opti.assessFitness_helper( opti_particle)\n",
    "    y_pred = X_test.apply(network.forwardCalculation, args = (weights, bias), axis = 1)\n",
    "    mse_arr.append(network.errorCalculation(y_pred, y_test))\n",
    "mse_comb2 = sum(mse_arr)/len(mse_arr)\n",
    "mse_comb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.28136310764321"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combination 3\n",
    "# Network layer (3, 3, 3)\n",
    "# All best PSO hyperparam except beta = 1.6\n",
    "\n",
    "# Set up network\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,1))\n",
    "\n",
    "# PSO Hyperparams\n",
    "swarmsize = 10\n",
    "alpha = 0.6\n",
    "beta = 1.6\n",
    "gamma = 1.5\n",
    "delta = 1.6\n",
    "epsilon = 0.4\n",
    "n_iter = 10\n",
    "\n",
    "mse_arr = []\n",
    "for i in range(10):\n",
    "    # Getting optimal position\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "\n",
    "    # Apply to test set\n",
    "    weights, bias = particle_swarm_opti.assessFitness_helper( opti_particle)\n",
    "    y_pred = X_test.apply(network.forwardCalculation, args = (weights, bias), axis = 1)\n",
    "    mse_arr.append(network.errorCalculation(y_pred, y_test))\n",
    "mse_comb3 = sum(mse_arr)/len(mse_arr)\n",
    "mse_comb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.909314781449874"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combination 4\n",
    "# Network layer (6, 4, 2)\n",
    "# All best PSO hyperparam except beta = 1.6\n",
    "\n",
    "# Set up network\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,6))\n",
    "network.add(layer(ActFunc.relu,4))\n",
    "network.add(layer(ActFunc.relu,2))\n",
    "network.add(layer(ActFunc.relu,1))\n",
    "\n",
    "# PSO Hyperparams\n",
    "swarmsize = 10\n",
    "alpha = 0.6\n",
    "beta = 1.6\n",
    "gamma = 1.5\n",
    "delta = 1.6\n",
    "epsilon = 0.4\n",
    "n_iter = 10\n",
    "\n",
    "mse_arr = []\n",
    "for i in range(10):\n",
    "    # Getting optimal position\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "\n",
    "    # Apply to test set\n",
    "    weights, bias = particle_swarm_opti.assessFitness_helper( opti_particle)\n",
    "    y_pred = X_test.apply(network.forwardCalculation, args = (weights, bias), axis = 1)\n",
    "    mse_arr.append(network.errorCalculation(y_pred, y_test))\n",
    "mse_comb4 = sum(mse_arr)/len(mse_arr)\n",
    "mse_comb4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.460693562014788"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combination 5\n",
    "# Network layer (6, 4, 2)\n",
    "# All best PSO hyperparam except alpha = 0.7\n",
    "\n",
    "# Set up network\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,6))\n",
    "network.add(layer(ActFunc.relu,4))\n",
    "network.add(layer(ActFunc.relu,2))\n",
    "network.add(layer(ActFunc.relu,1))\n",
    "\n",
    "# PSO Hyperparams\n",
    "swarmsize = 10\n",
    "alpha = 0.7\n",
    "beta = 2.4\n",
    "gamma = 1.5\n",
    "delta = 1.6\n",
    "epsilon = 0.4\n",
    "n_iter = 10\n",
    "\n",
    "mse_arr = []\n",
    "for i in range(10):\n",
    "    # Getting optimal position\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "\n",
    "    # Apply to test set\n",
    "    weights, bias = particle_swarm_opti.assessFitness_helper( opti_particle)\n",
    "    y_pred = X_test.apply(network.forwardCalculation, args = (weights, bias), axis = 1)\n",
    "    mse_arr.append(network.errorCalculation(y_pred, y_test))\n",
    "mse_comb5 = sum(mse_arr)/len(mse_arr)\n",
    "mse_comb5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.691696188951273"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combination 6\n",
    "# Network layer (3, 3, 3)\n",
    "# All best PSO hyperparam except alpha = 0.7\n",
    "\n",
    "# Set up network\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,1))\n",
    "\n",
    "# PSO Hyperparams\n",
    "swarmsize = 10\n",
    "alpha = 0.7\n",
    "beta = 2.4\n",
    "gamma = 1.5\n",
    "delta = 1.6\n",
    "epsilon = 0.4\n",
    "n_iter = 10\n",
    "\n",
    "mse_arr = []\n",
    "for i in range(10):\n",
    "    # Getting optimal position\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "\n",
    "    # Apply to test set\n",
    "    weights, bias = particle_swarm_opti.assessFitness_helper( opti_particle)\n",
    "    y_pred = X_test.apply(network.forwardCalculation, args = (weights, bias), axis = 1)\n",
    "    mse_arr.append(network.errorCalculation(y_pred, y_test))\n",
    "mse_comb6 = sum(mse_arr)/len(mse_arr)\n",
    "mse_comb6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best way of allocating solution evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.049228908961974"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Swarm size of 100 but number of iteration 10\n",
    "\n",
    "swarmsize = 100\n",
    "alpha = 0.7\n",
    "beta = 2\n",
    "gamma = 1.5\n",
    "delta = 1.5\n",
    "epsilon = 0.4\n",
    "n_iter = 10\n",
    "\n",
    "all_best = []\n",
    "for i in range(1):\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "    all_best.append(best_mae_arr[-1])\n",
    "avg_best_a = sum(all_best)/len(all_best)\n",
    "avg_best_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.48772890605923"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Swarm size of 10 but number of iteration 100\n",
    "\n",
    "swarmsize = 10\n",
    "alpha = 0.7\n",
    "beta = 2\n",
    "gamma = 1.5\n",
    "delta = 1.5\n",
    "epsilon = 0.4\n",
    "n_iter = 100\n",
    "\n",
    "all_best = []\n",
    "for i in range(1):\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "    all_best.append(best_mae_arr[-1])\n",
    "avg_best_b = sum(all_best)/len(all_best)\n",
    "avg_best_b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
