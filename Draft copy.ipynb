{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Multi-layer ANN\n",
    "\n",
    "Hyperparameters:\n",
    " 1. Number of nodes\n",
    " 2. Number of layers\n",
    " 3. Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from enum import Enum\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>blast_furnace_slag</th>\n",
       "      <th>fly_ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>coarse_aggregate</th>\n",
       "      <th>fine_aggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>concrete_compressive_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement  blast_furnace_slag  fly_ash  water  superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   coarse_aggregate  fine_aggregate   age  concrete_compressive_strength  \n",
       "0            1040.0            676.0   28                          79.99  \n",
       "1            1055.0            676.0   28                          61.89  \n",
       "2             932.0            594.0  270                          40.27  \n",
       "3             932.0            594.0  365                          41.05  \n",
       "4             978.4            825.5  360                          44.30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "concrete = pd.read_csv('data/concrete_data.csv')\n",
    "concrete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X and Y\n",
    "# Then separate test and train set\n",
    "# Also do the Cross-Validation (optional)\n",
    "X = concrete.drop('concrete_compressive_strength', axis = 1)\n",
    "y = concrete['concrete_compressive_strength']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.head()\n",
    "y_train = y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function\n",
    "def logistic(x):\n",
    "    return 1/(1 + math.exp(-x))\n",
    "\n",
    "def ReLU(x):\n",
    "    return max(0, x)\n",
    "\n",
    "def hyperbolic(x):\n",
    "    return math.tanh(x)\n",
    "\n",
    "class ActFunc(Enum):\n",
    "    log = logistic\n",
    "    relu = ReLU\n",
    "    hb = hyperbolic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network test!\n",
    "from neuralNet import neuralNet\n",
    "from layer import layer\n",
    "\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,6))\n",
    "network.add(layer(ActFunc.relu,4))\n",
    "network.add(layer(ActFunc.relu,2))\n",
    "network.add(layer(ActFunc.relu,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Implement the PSO\n",
    "\n",
    "Hyperparameters:\n",
    "1. Swarmsize\n",
    "2. Alpha\n",
    "3. Beta\n",
    "4. Gamma\n",
    "5. Delta\n",
    "6. Epsilon\n",
    "7. Number of iterations (epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.774276857296921"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PSO test!\n",
    "import pso\n",
    "\n",
    "swarmsize = 10\n",
    "alpha = 0.7\n",
    "beta = 2\n",
    "gamma = 1.5\n",
    "delta = 1.5\n",
    "epsilon = 0.4\n",
    "n_iter = 30\n",
    "\n",
    "all_best = []\n",
    "for i in range(10):\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "    all_best.append(best_mae_arr[-1])\n",
    "avg_best = sum(all_best)/len(all_best)\n",
    "avg_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3, 4 & 5: Exploring ANN and PSO hyperparameters on the concrete data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying different number of layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 9.21965117670373,\n",
       " 3: 8.694942828199865,\n",
       " 4: 6.728058881377542,\n",
       " 5: 8.028298138608836,\n",
       " 6: 7.841379543160424,\n",
       " 7: 8.281235597112111,\n",
       " 8: 7.746841099253055,\n",
       " 9: 7.62560583797931}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try neural network architectures\n",
    "# 2-10 layers\n",
    "# 3-10 neurons per layer\n",
    "\n",
    "layers = range(2,10)\n",
    "\n",
    "# Try different layers\n",
    "# Constant 4 neurons per layer, activation func relu\n",
    "\n",
    "avg_accuraciesForLayers = {}\n",
    "for numLayers in layers:\n",
    "    accuraciesForLayers = []\n",
    "    # Set up network\n",
    "    network = neuralNet()\n",
    "    for i in range(numLayers - 1):\n",
    "        network.add(layer(ActFunc.relu,4))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    for i in range(10):\n",
    "        layerTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter,prints=False)\n",
    "        opti_particle, best_mae_arr = layerTestPSO.optimise()\n",
    "        accuraciesForLayers.append(best_mae_arr[-1])\n",
    "    avg_accuraciesForLayers[numLayers] = sum(accuraciesForLayers)/len(accuraciesForLayers)\n",
    "avg_accuraciesForLayers\n",
    "\n",
    "# Best: 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 9.21965117670373,\n",
       " 3: 8.694942828199865,\n",
       " 4: 6.728058881377542,\n",
       " 5: 8.028298138608836,\n",
       " 6: 7.841379543160424,\n",
       " 7: 8.281235597112111,\n",
       " 8: 7.746841099253055,\n",
       " 9: 7.62560583797931}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuraciesForLayers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying different number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 9.621431009625852,\n",
       " 3: 7.302436047446126,\n",
       " 4: 7.768896104759547,\n",
       " 5: 7.493852665983627,\n",
       " 6: 7.691044686864342,\n",
       " 7: 7.542390043492209,\n",
       " 8: 9.666438187215467,\n",
       " 9: 8.138090623545514,\n",
       " 10: 11.60068150767477}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons = range(2,11)\n",
    "\n",
    "avg_accuraciesForNeuronCounts = {}\n",
    "\n",
    "for neuronCount in neurons:\n",
    "    accuraciesForNeuronCounts = []\n",
    "    # Set up network\n",
    "    network = neuralNet()\n",
    "    for i in range(3):\n",
    "        network.add(layer(ActFunc.relu,neuronCount))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    # Run optimisation 10 times\n",
    "    for i in range(10):\n",
    "        neuronsTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter,prints=False)\n",
    "        opti_particle, best_mae_arr = neuronsTestPSO.optimise()\n",
    "        accuraciesForNeuronCounts.append(best_mae_arr[-1])\n",
    "    avg_accuraciesForNeuronCounts[neuronCount] = sum(accuraciesForNeuronCounts)/len(accuraciesForNeuronCounts)\n",
    "avg_accuraciesForNeuronCounts\n",
    "\n",
    "# Best is 3 neurons per layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 9.621431009625852,\n",
       " 3: 7.302436047446126,\n",
       " 4: 7.768896104759547,\n",
       " 5: 7.493852665983627,\n",
       " 6: 7.691044686864342,\n",
       " 7: 7.542390043492209,\n",
       " 8: 9.666438187215467,\n",
       " 9: 8.138090623545514,\n",
       " 10: 11.60068150767477}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuraciesForNeuronCounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSO hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potential ranges of PSO parameters to try\n",
    "# Could try them like a gridsearch but its probably a bit too much for that, tuning one at a time is probably the way to go\n",
    "\n",
    "alphaRange = np.arange(0.4,0.9,0.1)\n",
    "betaRange = np.arange(1.5,2.5,0.1)\n",
    "gammaRange = np.arange(1.5,2.5,0.1)\n",
    "deltaRange = np.arange(1.5,2.5,0.1)\n",
    "epsilonRange = np.arange(0.1,0.5,0.1) # not sure about the range of the learning rate, might need to experiment or look for more sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuraciesForAlphas = {}\n",
    "\n",
    "for a in alphaRange:\n",
    "    accuraciesForAlphas = []\n",
    "    # Set up network\n",
    "    network = neuralNet()\n",
    "    for i in range(3):\n",
    "        network.add(layer(ActFunc.relu,3))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    for i in range(10):\n",
    "        alphaTestPSO = pso.PSO(X_train, y_train, network, swarmsize, a, beta, gamma, delta, epsilon, n_iter,prints=False)\n",
    "        opti_particle, best_mae_arr = alphaTestPSO.optimise()\n",
    "        accuraciesForAlphas.append(best_mae_arr[-1])\n",
    "    avg_accuraciesForAlphas[a] = sum(accuraciesForAlphas)/len(accuraciesForAlphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuraciesForBetas = {}\n",
    "\n",
    "for b in betaRange:\n",
    "    accuraciesForBetas = []\n",
    "    # Set up network\n",
    "    network = neuralNet()\n",
    "    for i in range(3):\n",
    "        network.add(layer(ActFunc.relu,3))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    for i in range(10):\n",
    "        betaTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, b, gamma, delta, epsilon, n_iter,prints=False)\n",
    "        opti_particle, best_mae_arr = betaTestPSO.optimise()\n",
    "        accuraciesForBetas.append(best_mae_arr[-1])\n",
    "    avg_accuraciesForBetas[b] = sum(accuraciesForBetas)/len(accuraciesForBetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuraciesForGammas = {}\n",
    "\n",
    "for g in gammaRange:\n",
    "    accuraciesForGammas = []\n",
    "    # Set up network\n",
    "    network = neuralNet()\n",
    "    for i in range(3):\n",
    "        network.add(layer(ActFunc.relu,3))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    for i in range(10):\n",
    "        gammaTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, g, delta, epsilon, n_iter,prints=False)\n",
    "        opti_particle, best_mae_arr = gammaTestPSO.optimise()\n",
    "        accuraciesForGammas.append(best_mae_arr[-1])\n",
    "    avg_accuraciesForGammas[g] = sum(accuraciesForGammas)/len(accuraciesForGammas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuraciesForDeltas = {}\n",
    "\n",
    "for d in deltaRange:\n",
    "    accuraciesForDeltas = []\n",
    "    # Set up network\n",
    "    network = neuralNet()\n",
    "    for i in range(3):\n",
    "        network.add(layer(ActFunc.relu,3))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    for i in range(10):\n",
    "        deltaTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, d, epsilon, n_iter,prints=False)\n",
    "        opti_particle, best_mae_arr = deltaTestPSO.optimise()\n",
    "        accuraciesForDeltas.append(best_mae_arr[-1])\n",
    "    avg_accuraciesForDeltas[d] = sum(accuraciesForDeltas)/len(accuraciesForDeltas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuraciesForEpsilons = {}\n",
    "\n",
    "for e in epsilonRange:\n",
    "    accuraciesForEpsilons = []\n",
    "\n",
    "    # Set up network\n",
    "    network = neuralNet()\n",
    "    for i in range(3):\n",
    "        network.add(layer(ActFunc.relu,3))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    for i in range(10):\n",
    "        epsilonTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, e, n_iter,prints=False)\n",
    "        opti_particle, best_mae_arr = epsilonTestPSO.optimise()\n",
    "        accuraciesForEpsilons.append(best_mae_arr[-1])\n",
    "    avg_accuraciesForEpsilons[e] = sum(accuraciesForEpsilons)/len(accuraciesForEpsilons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.4: 8.860196501459633,\n",
       " 0.5: 8.2379098950724,\n",
       " 0.6: 7.110065087727984,\n",
       " 0.7: 7.2878931664528865,\n",
       " 0.7999999999999999: 9.0732645962763}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuraciesForAlphas \n",
    "# Best: 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.5: 8.516299778627646,\n",
       " 1.6: 7.011187406384254,\n",
       " 1.7000000000000002: 7.812416612654917,\n",
       " 1.8000000000000003: 7.925430050171327,\n",
       " 1.9000000000000004: 8.045151693461928,\n",
       " 2.0000000000000004: 6.9823869332069375,\n",
       " 2.1000000000000005: 7.1066045001290465,\n",
       " 2.2000000000000006: 6.9562888079269385,\n",
       " 2.3000000000000007: 7.864588392568438,\n",
       " 2.400000000000001: 7.002258692825028}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuraciesForBetas\n",
    "# Best: 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.5: 7.210871845882357,\n",
       " 1.6: 7.738279599695611,\n",
       " 1.7000000000000002: 8.09298952370678,\n",
       " 1.8000000000000003: 8.056790202040146,\n",
       " 1.9000000000000004: 8.120420184184272,\n",
       " 2.0000000000000004: 7.821793604060557,\n",
       " 2.1000000000000005: 7.508174930808276,\n",
       " 2.2000000000000006: 7.93516743113936,\n",
       " 2.3000000000000007: 8.339347723489587,\n",
       " 2.400000000000001: 8.392637228211948}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuraciesForGammas\n",
    "# Best: 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.5: 8.379900171889163,\n",
       " 1.6: 6.988238214533515,\n",
       " 1.7000000000000002: 7.11907354920492,\n",
       " 1.8000000000000003: 7.903439839161075,\n",
       " 1.9000000000000004: 7.543201546568708,\n",
       " 2.0000000000000004: 7.785197906521475,\n",
       " 2.1000000000000005: 7.530628148972589,\n",
       " 2.2000000000000006: 7.39415145522085,\n",
       " 2.3000000000000007: 7.89501955474951,\n",
       " 2.400000000000001: 8.449577460947005}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuraciesForDeltas\n",
    "# Best: 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.1: 8.701346391959278,\n",
       " 0.2: 8.335282191027044,\n",
       " 0.30000000000000004: 8.864050130091199,\n",
       " 0.4: 7.10317112999507}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuraciesForEpsilons\n",
    "# Best: 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few best combination of hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.49464543637781"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combination 1\n",
    "# Network layer (3, 3, 3)\n",
    "# All best PSO hyperparam\n",
    "\n",
    "# Set up network\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,1))\n",
    "\n",
    "# PSO Hyperparams\n",
    "swarmsize = 10\n",
    "alpha = 0.6\n",
    "beta = 2.4\n",
    "gamma = 1.5\n",
    "delta = 1.6\n",
    "epsilon = 0.4\n",
    "n_iter = 30\n",
    "\n",
    "mse_arr = []\n",
    "for i in range(10):\n",
    "    # Getting optimal position\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "\n",
    "    # Apply to test set\n",
    "    weights, bias = particle_swarm_opti.assessFitness_helper( opti_particle)\n",
    "    y_pred = X_test.apply(network.forwardCalculation, args = (weights, bias), axis = 1)\n",
    "    mse_arr.append(network.errorCalculation(y_pred, y_test))\n",
    "mse_comb1 = sum(mse_arr)/len(mse_arr)\n",
    "mse_comb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.78756468175565"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combination 2\n",
    "# Network layer (6, 4, 2)\n",
    "# All best PSO hyperparam\n",
    "\n",
    "# Set up network\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,6))\n",
    "network.add(layer(ActFunc.relu,4))\n",
    "network.add(layer(ActFunc.relu,2))\n",
    "network.add(layer(ActFunc.relu,1))\n",
    "\n",
    "# PSO Hyperparams\n",
    "swarmsize = 10\n",
    "alpha = 0.6\n",
    "beta = 2.4\n",
    "gamma = 1.5\n",
    "delta = 1.6\n",
    "epsilon = 0.4\n",
    "n_iter = 30\n",
    "\n",
    "mse_arr = []\n",
    "for i in range(10):\n",
    "    # Getting optimal position\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "\n",
    "    # Apply to test set\n",
    "    weights, bias = particle_swarm_opti.assessFitness_helper( opti_particle)\n",
    "    y_pred = X_test.apply(network.forwardCalculation, args = (weights, bias), axis = 1)\n",
    "    mse_arr.append(network.errorCalculation(y_pred, y_test))\n",
    "mse_comb2 = sum(mse_arr)/len(mse_arr)\n",
    "mse_comb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.564897682321114"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combination 3\n",
    "# Network layer (3, 3, 3)\n",
    "# All best PSO hyperparam except beta = 1.6\n",
    "\n",
    "# Set up network\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,1))\n",
    "\n",
    "# PSO Hyperparams\n",
    "swarmsize = 10\n",
    "alpha = 0.6\n",
    "beta = 1.6\n",
    "gamma = 1.5\n",
    "delta = 1.6\n",
    "epsilon = 0.4\n",
    "n_iter = 30\n",
    "\n",
    "mse_arr = []\n",
    "for i in range(10):\n",
    "    # Getting optimal position\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "\n",
    "    # Apply to test set\n",
    "    weights, bias = particle_swarm_opti.assessFitness_helper( opti_particle)\n",
    "    y_pred = X_test.apply(network.forwardCalculation, args = (weights, bias), axis = 1)\n",
    "    mse_arr.append(network.errorCalculation(y_pred, y_test))\n",
    "mse_comb3 = sum(mse_arr)/len(mse_arr)\n",
    "mse_comb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.218381175457566"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combination 4\n",
    "# Network layer (6, 4, 2)\n",
    "# All best PSO hyperparam except beta = 1.6\n",
    "\n",
    "# Set up network\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,6))\n",
    "network.add(layer(ActFunc.relu,4))\n",
    "network.add(layer(ActFunc.relu,2))\n",
    "network.add(layer(ActFunc.relu,1))\n",
    "\n",
    "# PSO Hyperparams\n",
    "swarmsize = 10\n",
    "alpha = 0.6\n",
    "beta = 1.6\n",
    "gamma = 1.5\n",
    "delta = 1.6\n",
    "epsilon = 0.4\n",
    "n_iter = 30\n",
    "\n",
    "mse_arr = []\n",
    "for i in range(10):\n",
    "    # Getting optimal position\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "\n",
    "    # Apply to test set\n",
    "    weights, bias = particle_swarm_opti.assessFitness_helper( opti_particle)\n",
    "    y_pred = X_test.apply(network.forwardCalculation, args = (weights, bias), axis = 1)\n",
    "    mse_arr.append(network.errorCalculation(y_pred, y_test))\n",
    "mse_comb4 = sum(mse_arr)/len(mse_arr)\n",
    "mse_comb4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.589100273154656"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combination 5\n",
    "# Network layer (6, 4, 2)\n",
    "# All best PSO hyperparam except alpha = 0.7\n",
    "\n",
    "# Set up network\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,6))\n",
    "network.add(layer(ActFunc.relu,4))\n",
    "network.add(layer(ActFunc.relu,2))\n",
    "network.add(layer(ActFunc.relu,1))\n",
    "\n",
    "# PSO Hyperparams\n",
    "swarmsize = 10\n",
    "alpha = 0.7\n",
    "beta = 2.4\n",
    "gamma = 1.5\n",
    "delta = 1.6\n",
    "epsilon = 0.4\n",
    "n_iter = 30\n",
    "\n",
    "mse_arr = []\n",
    "for i in range(10):\n",
    "    # Getting optimal position\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "\n",
    "    # Apply to test set\n",
    "    weights, bias = particle_swarm_opti.assessFitness_helper( opti_particle)\n",
    "    y_pred = X_test.apply(network.forwardCalculation, args = (weights, bias), axis = 1)\n",
    "    mse_arr.append(network.errorCalculation(y_pred, y_test))\n",
    "mse_comb5 = sum(mse_arr)/len(mse_arr)\n",
    "mse_comb5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.543033560563112"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combination 6\n",
    "# Network layer (3, 3, 3)\n",
    "# All best PSO hyperparam except alpha = 0.7\n",
    "\n",
    "# Set up network\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,1))\n",
    "\n",
    "# PSO Hyperparams\n",
    "swarmsize = 10\n",
    "alpha = 0.7\n",
    "beta = 2.4\n",
    "gamma = 1.5\n",
    "delta = 1.6\n",
    "epsilon = 0.4\n",
    "n_iter = 30\n",
    "\n",
    "mse_arr = []\n",
    "for i in range(10):\n",
    "    # Getting optimal position\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "\n",
    "    # Apply to test set\n",
    "    weights, bias = particle_swarm_opti.assessFitness_helper( opti_particle)\n",
    "    y_pred = X_test.apply(network.forwardCalculation, args = (weights, bias), axis = 1)\n",
    "    mse_arr.append(network.errorCalculation(y_pred, y_test))\n",
    "mse_comb6 = sum(mse_arr)/len(mse_arr)\n",
    "mse_comb6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best way of allocating solution evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swarm size of 100 but number of iteration 10\n",
    "\n",
    "swarmsize = 100\n",
    "alpha = 0.7\n",
    "beta = 2\n",
    "gamma = 1.5\n",
    "delta = 1.5\n",
    "epsilon = 0.4\n",
    "n_iter = 10\n",
    "\n",
    "all_best = []\n",
    "for i in range(10):\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "    all_best.append(best_mae_arr[-1])\n",
    "avg_best_a = sum(all_best)/len(all_best)\n",
    "avg_best_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swarm size of 10 but number of iteration 100\n",
    "\n",
    "swarmsize = 10\n",
    "alpha = 0.7\n",
    "beta = 2\n",
    "gamma = 1.5\n",
    "delta = 1.5\n",
    "epsilon = 0.4\n",
    "n_iter = 100\n",
    "\n",
    "all_best = []\n",
    "for i in range(10):\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "    all_best.append(best_mae_arr[-1])\n",
    "avg_best_b = sum(all_best)/len(all_best)\n",
    "avg_best_b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
