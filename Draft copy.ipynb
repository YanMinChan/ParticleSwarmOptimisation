{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Multi-layer ANN\n",
    "\n",
    "Hyperparameters:\n",
    " 1. Number of nodes\n",
    " 2. Number of layers\n",
    " 3. Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from enum import Enum\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>blast_furnace_slag</th>\n",
       "      <th>fly_ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>coarse_aggregate</th>\n",
       "      <th>fine_aggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>concrete_compressive_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement  blast_furnace_slag  fly_ash  water  superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   coarse_aggregate  fine_aggregate   age  concrete_compressive_strength  \n",
       "0            1040.0            676.0   28                          79.99  \n",
       "1            1055.0            676.0   28                          61.89  \n",
       "2             932.0            594.0  270                          40.27  \n",
       "3             932.0            594.0  365                          41.05  \n",
       "4             978.4            825.5  360                          44.30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "concrete = pd.read_csv('data/concrete_data.csv')\n",
    "concrete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X and Y\n",
    "# Then separate test and train set\n",
    "# Also do the Cross-Validation (optional)\n",
    "X = concrete.drop('concrete_compressive_strength', axis = 1)\n",
    "y = concrete['concrete_compressive_strength']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.7, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function\n",
    "def logistic(x):\n",
    "    return 1/(1 + math.exp(-x))\n",
    "\n",
    "def ReLU(x):\n",
    "    return max(0, x)\n",
    "\n",
    "def hyperbolic(x):\n",
    "    return math.tanh(x)\n",
    "\n",
    "class ActFunc(Enum):\n",
    "    log = logistic\n",
    "    relu = ReLU\n",
    "    hb = hyperbolic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network test!\n",
    "from neuralNet import neuralNet\n",
    "from layer import layer\n",
    "\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,6))\n",
    "network.add(layer(ActFunc.relu,4))\n",
    "network.add(layer(ActFunc.relu,2))\n",
    "network.add(layer(ActFunc.relu,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Implement the PSO\n",
    "\n",
    "Hyperparameters:\n",
    "1. Swarmsize\n",
    "2. Alpha\n",
    "3. Beta\n",
    "4. Gamma\n",
    "5. Delta\n",
    "6. Epsilon\n",
    "7. Number of iterations (epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.60548812272804"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PSO test!\n",
    "import pso\n",
    "\n",
    "swarmsize = 10\n",
    "alpha = 0.7\n",
    "beta = 2\n",
    "gamma = 1.5\n",
    "delta = 1.5\n",
    "epsilon = 0.4\n",
    "n_iter = 10\n",
    "\n",
    "all_best = []\n",
    "for i in range(1):\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "    all_best.append(best_mae_arr[-1])\n",
    "avg_best = sum(all_best)/len(all_best)\n",
    "avg_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3, 4 & 5: Exploring ANN and PSO hyperparameters on the concrete data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying different number of layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m     19\u001b[0m     layerTestPSO \u001b[38;5;241m=\u001b[39m pso\u001b[38;5;241m.\u001b[39mPSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter,prints\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 20\u001b[0m     opti_particle, best_mae_arr \u001b[38;5;241m=\u001b[39m layerTestPSO\u001b[38;5;241m.\u001b[39moptimise()\n\u001b[0;32m     21\u001b[0m     accuraciesForLayers\u001b[38;5;241m.\u001b[39mappend(best_mae_arr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     22\u001b[0m avg_accuraciesForLayers[numLayers] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(accuraciesForLayers)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(accuraciesForLayers)\n",
      "File \u001b[1;32mc:\\Users\\chany\\OneDrive\\Desktop\\Academic\\MSc\\Biological Inspired Computing\\CW\\pso.py:138\u001b[0m, in \u001b[0;36mPSO.optimise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m x_star \u001b[38;5;241m=\u001b[39m particle\u001b[38;5;241m.\u001b[39mprevBest\n\u001b[0;32m    137\u001b[0m x_plus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfittestLoc(particle\u001b[38;5;241m.\u001b[39minformant)\n\u001b[1;32m--> 138\u001b[0m x_prime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfittestLoc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparticles)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# Do the change velo\u001b[39;00m\n\u001b[0;32m    141\u001b[0m particle\u001b[38;5;241m.\u001b[39mchangeVelo(particle\u001b[38;5;241m.\u001b[39mpos, x_star, x_plus, x_prime)\n",
      "File \u001b[1;32mc:\\Users\\chany\\OneDrive\\Desktop\\Academic\\MSc\\Biological Inspired Computing\\CW\\pso.py:54\u001b[0m, in \u001b[0;36mPSO.fittestLoc\u001b[1;34m(self, someParticles)\u001b[0m\n\u001b[0;32m     52\u001b[0m fittest_mae \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m someParticles:\n\u001b[1;32m---> 54\u001b[0m     mae \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massessFitness(p\u001b[38;5;241m.\u001b[39mpos, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my)\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fittest_mae \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m mae \u001b[38;5;241m<\u001b[39m fittest_mae:\n\u001b[0;32m     56\u001b[0m         fittest_mae \u001b[38;5;241m=\u001b[39m mae\n",
      "File \u001b[1;32mc:\\Users\\chany\\OneDrive\\Desktop\\Academic\\MSc\\Biological Inspired Computing\\CW\\pso.py:89\u001b[0m, in \u001b[0;36mPSO.assessFitness\u001b[1;34m(self, pos, y)\u001b[0m\n\u001b[0;32m     85\u001b[0m weights_arr, bias_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massessFitness_helper(pos)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Calculate the pred y\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m yhat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mforwardCalculation, args \u001b[38;5;241m=\u001b[39m (weights_arr, bias_arr), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# print(self.X.iloc[0])\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# print(self.X.iloc[1])\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# print(\"First\", self.network.forwardCalculation(self.X.iloc[0], weights_arr, bias_arr))\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# print(\"Second\", self.network.forwardCalculation(self.X.iloc[1], weights_arr, bias_arr))\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m#print(\"yhat:\\n\", yhat)\u001b[39;00m\n\u001b[0;32m     95\u001b[0m mae \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39merrorCalculation(yhat, y)\n",
      "File \u001b[1;32mc:\\Users\\chany\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\chany\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\chany\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\chany\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\chany\\OneDrive\\Desktop\\Academic\\MSc\\Biological Inspired Computing\\CW\\neuralNet.py:14\u001b[0m, in \u001b[0;36mneuralNet.forwardCalculation\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m     12\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 14\u001b[0m     output \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mlayerCalculation(\u001b[38;5;28minput\u001b[39m, weight[i], bias[i])\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m#print(\"input\", input)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m output\n",
      "File \u001b[1;32mc:\\Users\\chany\\OneDrive\\Desktop\\Academic\\MSc\\Biological Inspired Computing\\CW\\layer.py:33\u001b[0m, in \u001b[0;36mlayer.layerCalculation\u001b[1;34m(self, inputs, weights, bias)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# initialize all weights as 1 in case we do not have any specified\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# it is now an 2D array, lists containing weights for a single neuron (one weight for each input) grouped into a list (one list of weights for every neuron)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# if weights == None:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# if bias == None:\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#     self.bias = [1] * len(self.perceptronArr)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, perc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperceptronArr):\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput[i] \u001b[38;5;241m=\u001b[39m perc\u001b[38;5;241m.\u001b[39mCalculateOutput(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[i], \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39minputs, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias[i])\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\n",
      "File \u001b[1;32mc:\\Users\\chany\\OneDrive\\Desktop\\Academic\\MSc\\Biological Inspired Computing\\CW\\perceptron.py:12\u001b[0m, in \u001b[0;36mPerceptron.CalculateOutput\u001b[1;34m(self, weights, input, bias)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mCalculateOutput\u001b[39m(\u001b[38;5;28mself\u001b[39m, weights, \u001b[38;5;28minput\u001b[39m, bias):\n\u001b[1;32m---> 12\u001b[0m     z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28minput\u001b[39m)\u001b[38;5;241m.\u001b[39mT,np\u001b[38;5;241m.\u001b[39marray(weights)) \u001b[38;5;241m+\u001b[39m bias\n\u001b[0;32m     13\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivationFunc(z)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m s\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Try neural network architectures\n",
    "# 2-10 layers\n",
    "# 3-10 neurons per layer\n",
    "\n",
    "layers = range(2,10)\n",
    "\n",
    "# Try different layers\n",
    "# Constant 4 neurons per layer, activation func relu\n",
    "\n",
    "avg_accuraciesForLayers = {}\n",
    "for numLayers in layers:\n",
    "    accuraciesForLayers = []\n",
    "    # Set up network\n",
    "    network = neuralNet()\n",
    "    for i in range(numLayers - 1):\n",
    "        network.add(layer(ActFunc.relu,4))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    for i in range(1):\n",
    "        layerTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter,prints=False)\n",
    "        opti_particle, best_mae_arr = layerTestPSO.optimise()\n",
    "        accuraciesForLayers.append(best_mae_arr[-1])\n",
    "    avg_accuraciesForLayers[numLayers] = sum(accuraciesForLayers)/len(accuraciesForLayers)\n",
    "avg_accuraciesForLayers\n",
    "\n",
    "# Best: 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 9.21965117670373,\n",
       " 3: 8.694942828199865,\n",
       " 4: 6.728058881377542,\n",
       " 5: 8.028298138608836,\n",
       " 6: 7.841379543160424,\n",
       " 7: 8.281235597112111,\n",
       " 8: 7.746841099253055,\n",
       " 9: 7.62560583797931}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuraciesForLayers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying different number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 9.621431009625852,\n",
       " 3: 7.302436047446126,\n",
       " 4: 7.768896104759547,\n",
       " 5: 7.493852665983627,\n",
       " 6: 7.691044686864342,\n",
       " 7: 7.542390043492209,\n",
       " 8: 9.666438187215467,\n",
       " 9: 8.138090623545514,\n",
       " 10: 11.60068150767477}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons = range(2,11)\n",
    "\n",
    "avg_accuraciesForNeuronCounts = {}\n",
    "\n",
    "for neuronCount in neurons:\n",
    "    accuraciesForNeuronCounts = []\n",
    "    # Set up network\n",
    "    network = neuralNet()\n",
    "    for i in range(3):\n",
    "        network.add(layer(ActFunc.relu,neuronCount))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    # Run optimisation 10 times\n",
    "    for i in range(1):\n",
    "        neuronsTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter,prints=False)\n",
    "        opti_particle, best_mae_arr = neuronsTestPSO.optimise()\n",
    "        accuraciesForNeuronCounts.append(best_mae_arr[-1])\n",
    "    avg_accuraciesForNeuronCounts[neuronCount] = sum(accuraciesForNeuronCounts)/len(accuraciesForNeuronCounts)\n",
    "avg_accuraciesForNeuronCounts\n",
    "\n",
    "# Best is 3 neurons per layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 9.621431009625852,\n",
       " 3: 7.302436047446126,\n",
       " 4: 7.768896104759547,\n",
       " 5: 7.493852665983627,\n",
       " 6: 7.691044686864342,\n",
       " 7: 7.542390043492209,\n",
       " 8: 9.666438187215467,\n",
       " 9: 8.138090623545514,\n",
       " 10: 11.60068150767477}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuraciesForNeuronCounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSO hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potential ranges of PSO parameters to try\n",
    "# Could try them like a gridsearch but its probably a bit too much for that, tuning one at a time is probably the way to go\n",
    "\n",
    "alphaRange = np.arange(0.4,0.9,0.1)\n",
    "betaRange = np.arange(1.5,2.5,0.1)\n",
    "gammaRange = np.arange(1.5,2.5,0.1)\n",
    "deltaRange = np.arange(1.5,2.5,0.1)\n",
    "epsilonRange = np.arange(0.1,0.5,0.1) # not sure about the range of the learning rate, might need to experiment or look for more sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuraciesForAlphas = {}\n",
    "\n",
    "for a in alphaRange:\n",
    "    accuraciesForAlphas = []\n",
    "    # Set up network\n",
    "    network = neuralNet()\n",
    "    for i in range(3):\n",
    "        network.add(layer(ActFunc.relu,3))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    for i in range(1):\n",
    "        alphaTestPSO = pso.PSO(X_train, y_train, network, swarmsize, a, beta, gamma, delta, epsilon, n_iter,prints=False)\n",
    "        opti_particle, best_mae_arr = alphaTestPSO.optimise()\n",
    "        accuraciesForAlphas.append(best_mae_arr[-1])\n",
    "    avg_accuraciesForAlphas[a] = sum(accuraciesForAlphas)/len(accuraciesForAlphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuraciesForBetas = {}\n",
    "\n",
    "for b in betaRange:\n",
    "    accuraciesForBetas = []\n",
    "    # Set up network\n",
    "    network = neuralNet()\n",
    "    for i in range(3):\n",
    "        network.add(layer(ActFunc.relu,3))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    for i in range(1):\n",
    "        betaTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, b, gamma, delta, epsilon, n_iter,prints=False)\n",
    "        opti_particle, best_mae_arr = betaTestPSO.optimise()\n",
    "        accuraciesForBetas.append(best_mae_arr[-1])\n",
    "    avg_accuraciesForBetas[b] = sum(accuraciesForBetas)/len(accuraciesForBetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuraciesForGammas = {}\n",
    "\n",
    "for g in gammaRange:\n",
    "    accuraciesForGammas = []\n",
    "    # Set up network\n",
    "    network = neuralNet()\n",
    "    for i in range(3):\n",
    "        network.add(layer(ActFunc.relu,3))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    for i in range(1):\n",
    "        gammaTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, g, delta, epsilon, n_iter,prints=False)\n",
    "        opti_particle, best_mae_arr = gammaTestPSO.optimise()\n",
    "        accuraciesForGammas.append(best_mae_arr[-1])\n",
    "    avg_accuraciesForGammas[g] = sum(accuraciesForGammas)/len(accuraciesForGammas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuraciesForDeltas = {}\n",
    "\n",
    "for d in deltaRange:\n",
    "    accuraciesForDeltas = []\n",
    "    # Set up network\n",
    "    network = neuralNet()\n",
    "    for i in range(3):\n",
    "        network.add(layer(ActFunc.relu,3))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    for i in range(1):\n",
    "        deltaTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, d, epsilon, n_iter,prints=False)\n",
    "        opti_particle, best_mae_arr = deltaTestPSO.optimise()\n",
    "        accuraciesForDeltas.append(best_mae_arr[-1])\n",
    "    avg_accuraciesForDeltas[d] = sum(accuraciesForDeltas)/len(accuraciesForDeltas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuraciesForEpsilons = {}\n",
    "\n",
    "for e in epsilonRange:\n",
    "    accuraciesForEpsilons = []\n",
    "\n",
    "    # Set up network\n",
    "    network = neuralNet()\n",
    "    for i in range(3):\n",
    "        network.add(layer(ActFunc.relu,3))\n",
    "    network.add(layer(ActFunc.relu,1))\n",
    "    for i in range(1):\n",
    "        epsilonTestPSO = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, e, n_iter,prints=False)\n",
    "        opti_particle, best_mae_arr = epsilonTestPSO.optimise()\n",
    "        accuraciesForEpsilons.append(best_mae_arr[-1])\n",
    "    avg_accuraciesForEpsilons[e] = sum(accuraciesForEpsilons)/len(accuraciesForEpsilons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.4: 8.860196501459633,\n",
       " 0.5: 8.2379098950724,\n",
       " 0.6: 7.110065087727984,\n",
       " 0.7: 7.2878931664528865,\n",
       " 0.7999999999999999: 9.0732645962763}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuraciesForAlphas \n",
    "# Best: 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.5: 8.516299778627646,\n",
       " 1.6: 7.011187406384254,\n",
       " 1.7000000000000002: 7.812416612654917,\n",
       " 1.8000000000000003: 7.925430050171327,\n",
       " 1.9000000000000004: 8.045151693461928,\n",
       " 2.0000000000000004: 6.9823869332069375,\n",
       " 2.1000000000000005: 7.1066045001290465,\n",
       " 2.2000000000000006: 6.9562888079269385,\n",
       " 2.3000000000000007: 7.864588392568438,\n",
       " 2.400000000000001: 7.002258692825028}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuraciesForBetas\n",
    "# Best: 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.5: 7.210871845882357,\n",
       " 1.6: 7.738279599695611,\n",
       " 1.7000000000000002: 8.09298952370678,\n",
       " 1.8000000000000003: 8.056790202040146,\n",
       " 1.9000000000000004: 8.120420184184272,\n",
       " 2.0000000000000004: 7.821793604060557,\n",
       " 2.1000000000000005: 7.508174930808276,\n",
       " 2.2000000000000006: 7.93516743113936,\n",
       " 2.3000000000000007: 8.339347723489587,\n",
       " 2.400000000000001: 8.392637228211948}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuraciesForGammas\n",
    "# Best: 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.5: 8.379900171889163,\n",
       " 1.6: 6.988238214533515,\n",
       " 1.7000000000000002: 7.11907354920492,\n",
       " 1.8000000000000003: 7.903439839161075,\n",
       " 1.9000000000000004: 7.543201546568708,\n",
       " 2.0000000000000004: 7.785197906521475,\n",
       " 2.1000000000000005: 7.530628148972589,\n",
       " 2.2000000000000006: 7.39415145522085,\n",
       " 2.3000000000000007: 7.89501955474951,\n",
       " 2.400000000000001: 8.449577460947005}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuraciesForDeltas\n",
    "# Best: 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.1: 8.701346391959278,\n",
       " 0.2: 8.335282191027044,\n",
       " 0.30000000000000004: 8.864050130091199,\n",
       " 0.4: 7.10317112999507}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuraciesForEpsilons\n",
    "# Best: 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few best combination of hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.49464543637781"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combination 1\n",
    "# Network layer (3, 3, 3)\n",
    "# All best PSO hyperparam\n",
    "\n",
    "# Set up network\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,1))\n",
    "\n",
    "# PSO Hyperparams\n",
    "swarmsize = 10\n",
    "alpha = 0.6\n",
    "beta = 2.4\n",
    "gamma = 1.5\n",
    "delta = 1.6\n",
    "epsilon = 0.4\n",
    "n_iter = 10\n",
    "\n",
    "mse_arr = []\n",
    "for i in range(10):\n",
    "    # Getting optimal position\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "\n",
    "    # Apply to test set\n",
    "    weights, bias = particle_swarm_opti.assessFitness_helper( opti_particle)\n",
    "    y_pred = X_test.apply(network.forwardCalculation, args = (weights, bias), axis = 1)\n",
    "    mse_arr.append(network.errorCalculation(y_pred, y_test))\n",
    "mse_comb1 = sum(mse_arr)/len(mse_arr)\n",
    "mse_comb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.78756468175565"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combination 2\n",
    "# Network layer (6, 4, 2)\n",
    "# All best PSO hyperparam\n",
    "\n",
    "# Set up network\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,6))\n",
    "network.add(layer(ActFunc.relu,4))\n",
    "network.add(layer(ActFunc.relu,2))\n",
    "network.add(layer(ActFunc.relu,1))\n",
    "\n",
    "# PSO Hyperparams\n",
    "swarmsize = 10\n",
    "alpha = 0.6\n",
    "beta = 2.4\n",
    "gamma = 1.5\n",
    "delta = 1.6\n",
    "epsilon = 0.4\n",
    "n_iter = 10\n",
    "\n",
    "mse_arr = []\n",
    "for i in range(10):\n",
    "    # Getting optimal position\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "\n",
    "    # Apply to test set\n",
    "    weights, bias = particle_swarm_opti.assessFitness_helper( opti_particle)\n",
    "    y_pred = X_test.apply(network.forwardCalculation, args = (weights, bias), axis = 1)\n",
    "    mse_arr.append(network.errorCalculation(y_pred, y_test))\n",
    "mse_comb2 = sum(mse_arr)/len(mse_arr)\n",
    "mse_comb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.564897682321114"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combination 3\n",
    "# Network layer (3, 3, 3)\n",
    "# All best PSO hyperparam except beta = 1.6\n",
    "\n",
    "# Set up network\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,1))\n",
    "\n",
    "# PSO Hyperparams\n",
    "swarmsize = 10\n",
    "alpha = 0.6\n",
    "beta = 1.6\n",
    "gamma = 1.5\n",
    "delta = 1.6\n",
    "epsilon = 0.4\n",
    "n_iter = 10\n",
    "\n",
    "mse_arr = []\n",
    "for i in range(10):\n",
    "    # Getting optimal position\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "\n",
    "    # Apply to test set\n",
    "    weights, bias = particle_swarm_opti.assessFitness_helper( opti_particle)\n",
    "    y_pred = X_test.apply(network.forwardCalculation, args = (weights, bias), axis = 1)\n",
    "    mse_arr.append(network.errorCalculation(y_pred, y_test))\n",
    "mse_comb3 = sum(mse_arr)/len(mse_arr)\n",
    "mse_comb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.218381175457566"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combination 4\n",
    "# Network layer (6, 4, 2)\n",
    "# All best PSO hyperparam except beta = 1.6\n",
    "\n",
    "# Set up network\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,6))\n",
    "network.add(layer(ActFunc.relu,4))\n",
    "network.add(layer(ActFunc.relu,2))\n",
    "network.add(layer(ActFunc.relu,1))\n",
    "\n",
    "# PSO Hyperparams\n",
    "swarmsize = 10\n",
    "alpha = 0.6\n",
    "beta = 1.6\n",
    "gamma = 1.5\n",
    "delta = 1.6\n",
    "epsilon = 0.4\n",
    "n_iter = 10\n",
    "\n",
    "mse_arr = []\n",
    "for i in range(10):\n",
    "    # Getting optimal position\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "\n",
    "    # Apply to test set\n",
    "    weights, bias = particle_swarm_opti.assessFitness_helper( opti_particle)\n",
    "    y_pred = X_test.apply(network.forwardCalculation, args = (weights, bias), axis = 1)\n",
    "    mse_arr.append(network.errorCalculation(y_pred, y_test))\n",
    "mse_comb4 = sum(mse_arr)/len(mse_arr)\n",
    "mse_comb4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.589100273154656"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combination 5\n",
    "# Network layer (6, 4, 2)\n",
    "# All best PSO hyperparam except alpha = 0.7\n",
    "\n",
    "# Set up network\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,6))\n",
    "network.add(layer(ActFunc.relu,4))\n",
    "network.add(layer(ActFunc.relu,2))\n",
    "network.add(layer(ActFunc.relu,1))\n",
    "\n",
    "# PSO Hyperparams\n",
    "swarmsize = 10\n",
    "alpha = 0.7\n",
    "beta = 2.4\n",
    "gamma = 1.5\n",
    "delta = 1.6\n",
    "epsilon = 0.4\n",
    "n_iter = 10\n",
    "\n",
    "mse_arr = []\n",
    "for i in range(10):\n",
    "    # Getting optimal position\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "\n",
    "    # Apply to test set\n",
    "    weights, bias = particle_swarm_opti.assessFitness_helper( opti_particle)\n",
    "    y_pred = X_test.apply(network.forwardCalculation, args = (weights, bias), axis = 1)\n",
    "    mse_arr.append(network.errorCalculation(y_pred, y_test))\n",
    "mse_comb5 = sum(mse_arr)/len(mse_arr)\n",
    "mse_comb5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.543033560563112"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combination 6\n",
    "# Network layer (3, 3, 3)\n",
    "# All best PSO hyperparam except alpha = 0.7\n",
    "\n",
    "# Set up network\n",
    "network = neuralNet()\n",
    "\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,3))\n",
    "network.add(layer(ActFunc.relu,1))\n",
    "\n",
    "# PSO Hyperparams\n",
    "swarmsize = 10\n",
    "alpha = 0.7\n",
    "beta = 2.4\n",
    "gamma = 1.5\n",
    "delta = 1.6\n",
    "epsilon = 0.4\n",
    "n_iter = 10\n",
    "\n",
    "mse_arr = []\n",
    "for i in range(10):\n",
    "    # Getting optimal position\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "\n",
    "    # Apply to test set\n",
    "    weights, bias = particle_swarm_opti.assessFitness_helper( opti_particle)\n",
    "    y_pred = X_test.apply(network.forwardCalculation, args = (weights, bias), axis = 1)\n",
    "    mse_arr.append(network.errorCalculation(y_pred, y_test))\n",
    "mse_comb6 = sum(mse_arr)/len(mse_arr)\n",
    "mse_comb6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best way of allocating solution evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swarm size of 100 but number of iteration 10\n",
    "\n",
    "swarmsize = 100\n",
    "alpha = 0.7\n",
    "beta = 2\n",
    "gamma = 1.5\n",
    "delta = 1.5\n",
    "epsilon = 0.4\n",
    "n_iter = 10\n",
    "\n",
    "all_best = []\n",
    "for i in range(1):\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "    all_best.append(best_mae_arr[-1])\n",
    "avg_best_a = sum(all_best)/len(all_best)\n",
    "avg_best_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swarm size of 10 but number of iteration 100\n",
    "\n",
    "swarmsize = 10\n",
    "alpha = 0.7\n",
    "beta = 2\n",
    "gamma = 1.5\n",
    "delta = 1.5\n",
    "epsilon = 0.4\n",
    "n_iter = 100\n",
    "\n",
    "all_best = []\n",
    "for i in range(1):\n",
    "    particle_swarm_opti = pso.PSO(X_train, y_train, network, swarmsize, alpha, beta, gamma, delta, epsilon, n_iter, prints=False)\n",
    "    opti_particle, best_mae_arr = particle_swarm_opti.optimise()\n",
    "    all_best.append(best_mae_arr[-1])\n",
    "avg_best_b = sum(all_best)/len(all_best)\n",
    "avg_best_b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
